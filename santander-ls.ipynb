{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.csv', 'sample_submission.csv', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "1fefeb3b0c86896b6683fbfb19d34a07997165b4"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "test_df = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "d0221e270a8923ba07854a431975f9885853297f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200000, 201), (200000, 202))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape, train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "52b0a36d1937489e9c0624b15ccbf9f6f181d151"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>var_10</th>\n",
       "      <th>var_11</th>\n",
       "      <th>var_12</th>\n",
       "      <th>var_13</th>\n",
       "      <th>var_14</th>\n",
       "      <th>var_15</th>\n",
       "      <th>var_16</th>\n",
       "      <th>var_17</th>\n",
       "      <th>var_18</th>\n",
       "      <th>var_19</th>\n",
       "      <th>var_20</th>\n",
       "      <th>var_21</th>\n",
       "      <th>var_22</th>\n",
       "      <th>var_23</th>\n",
       "      <th>var_24</th>\n",
       "      <th>var_25</th>\n",
       "      <th>var_26</th>\n",
       "      <th>var_27</th>\n",
       "      <th>var_28</th>\n",
       "      <th>var_29</th>\n",
       "      <th>var_30</th>\n",
       "      <th>var_31</th>\n",
       "      <th>var_32</th>\n",
       "      <th>var_33</th>\n",
       "      <th>var_34</th>\n",
       "      <th>var_35</th>\n",
       "      <th>var_36</th>\n",
       "      <th>var_37</th>\n",
       "      <th>...</th>\n",
       "      <th>var_160</th>\n",
       "      <th>var_161</th>\n",
       "      <th>var_162</th>\n",
       "      <th>var_163</th>\n",
       "      <th>var_164</th>\n",
       "      <th>var_165</th>\n",
       "      <th>var_166</th>\n",
       "      <th>var_167</th>\n",
       "      <th>var_168</th>\n",
       "      <th>var_169</th>\n",
       "      <th>var_170</th>\n",
       "      <th>var_171</th>\n",
       "      <th>var_172</th>\n",
       "      <th>var_173</th>\n",
       "      <th>var_174</th>\n",
       "      <th>var_175</th>\n",
       "      <th>var_176</th>\n",
       "      <th>var_177</th>\n",
       "      <th>var_178</th>\n",
       "      <th>var_179</th>\n",
       "      <th>var_180</th>\n",
       "      <th>var_181</th>\n",
       "      <th>var_182</th>\n",
       "      <th>var_183</th>\n",
       "      <th>var_184</th>\n",
       "      <th>var_185</th>\n",
       "      <th>var_186</th>\n",
       "      <th>var_187</th>\n",
       "      <th>var_188</th>\n",
       "      <th>var_189</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>2.9252</td>\n",
       "      <td>3.1821</td>\n",
       "      <td>14.0137</td>\n",
       "      <td>0.5745</td>\n",
       "      <td>8.7989</td>\n",
       "      <td>14.5691</td>\n",
       "      <td>5.7487</td>\n",
       "      <td>-7.2393</td>\n",
       "      <td>4.2840</td>\n",
       "      <td>30.7133</td>\n",
       "      <td>10.5350</td>\n",
       "      <td>16.2191</td>\n",
       "      <td>2.5791</td>\n",
       "      <td>2.4716</td>\n",
       "      <td>14.3831</td>\n",
       "      <td>13.4325</td>\n",
       "      <td>-5.1488</td>\n",
       "      <td>-0.4073</td>\n",
       "      <td>4.9306</td>\n",
       "      <td>5.9965</td>\n",
       "      <td>-0.3085</td>\n",
       "      <td>12.9041</td>\n",
       "      <td>-3.8766</td>\n",
       "      <td>16.8911</td>\n",
       "      <td>11.1920</td>\n",
       "      <td>10.5785</td>\n",
       "      <td>0.6764</td>\n",
       "      <td>7.8871</td>\n",
       "      <td>...</td>\n",
       "      <td>15.4576</td>\n",
       "      <td>5.3133</td>\n",
       "      <td>3.6159</td>\n",
       "      <td>5.0384</td>\n",
       "      <td>6.6760</td>\n",
       "      <td>12.6644</td>\n",
       "      <td>2.7004</td>\n",
       "      <td>-0.6975</td>\n",
       "      <td>9.5981</td>\n",
       "      <td>5.4879</td>\n",
       "      <td>-4.7645</td>\n",
       "      <td>-8.4254</td>\n",
       "      <td>20.8773</td>\n",
       "      <td>3.1531</td>\n",
       "      <td>18.5618</td>\n",
       "      <td>7.7423</td>\n",
       "      <td>-10.1245</td>\n",
       "      <td>13.7241</td>\n",
       "      <td>-3.5189</td>\n",
       "      <td>1.7202</td>\n",
       "      <td>-8.4051</td>\n",
       "      <td>9.0164</td>\n",
       "      <td>3.0657</td>\n",
       "      <td>14.3691</td>\n",
       "      <td>25.8398</td>\n",
       "      <td>5.8764</td>\n",
       "      <td>11.8411</td>\n",
       "      <td>-19.7159</td>\n",
       "      <td>17.5743</td>\n",
       "      <td>0.5857</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>-0.4032</td>\n",
       "      <td>8.0585</td>\n",
       "      <td>14.0239</td>\n",
       "      <td>8.4135</td>\n",
       "      <td>5.4345</td>\n",
       "      <td>13.7003</td>\n",
       "      <td>13.8275</td>\n",
       "      <td>-15.5849</td>\n",
       "      <td>7.8000</td>\n",
       "      <td>28.5708</td>\n",
       "      <td>3.4287</td>\n",
       "      <td>2.7407</td>\n",
       "      <td>8.5524</td>\n",
       "      <td>3.3716</td>\n",
       "      <td>6.9779</td>\n",
       "      <td>13.8910</td>\n",
       "      <td>-11.7684</td>\n",
       "      <td>-2.5586</td>\n",
       "      <td>5.0464</td>\n",
       "      <td>0.5481</td>\n",
       "      <td>-9.2987</td>\n",
       "      <td>7.8755</td>\n",
       "      <td>1.2859</td>\n",
       "      <td>19.3710</td>\n",
       "      <td>11.3702</td>\n",
       "      <td>0.7399</td>\n",
       "      <td>2.7995</td>\n",
       "      <td>5.8434</td>\n",
       "      <td>...</td>\n",
       "      <td>29.4846</td>\n",
       "      <td>5.8683</td>\n",
       "      <td>3.8208</td>\n",
       "      <td>15.8348</td>\n",
       "      <td>-5.0121</td>\n",
       "      <td>15.1345</td>\n",
       "      <td>3.2003</td>\n",
       "      <td>9.3192</td>\n",
       "      <td>3.8821</td>\n",
       "      <td>5.7999</td>\n",
       "      <td>5.5378</td>\n",
       "      <td>5.0988</td>\n",
       "      <td>22.0330</td>\n",
       "      <td>5.5134</td>\n",
       "      <td>30.2645</td>\n",
       "      <td>10.4968</td>\n",
       "      <td>-7.2352</td>\n",
       "      <td>16.5721</td>\n",
       "      <td>-7.3477</td>\n",
       "      <td>11.0752</td>\n",
       "      <td>-5.5937</td>\n",
       "      <td>9.4878</td>\n",
       "      <td>-14.9100</td>\n",
       "      <td>9.4245</td>\n",
       "      <td>22.5441</td>\n",
       "      <td>-4.8622</td>\n",
       "      <td>7.6543</td>\n",
       "      <td>-15.9319</td>\n",
       "      <td>13.3175</td>\n",
       "      <td>-0.3566</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>-0.3249</td>\n",
       "      <td>-11.2648</td>\n",
       "      <td>14.1929</td>\n",
       "      <td>7.3124</td>\n",
       "      <td>7.5244</td>\n",
       "      <td>14.6472</td>\n",
       "      <td>7.6782</td>\n",
       "      <td>-1.7395</td>\n",
       "      <td>4.7011</td>\n",
       "      <td>20.4775</td>\n",
       "      <td>17.7559</td>\n",
       "      <td>18.1377</td>\n",
       "      <td>1.2145</td>\n",
       "      <td>3.5137</td>\n",
       "      <td>5.6777</td>\n",
       "      <td>13.2177</td>\n",
       "      <td>-7.9940</td>\n",
       "      <td>-2.9029</td>\n",
       "      <td>5.8463</td>\n",
       "      <td>6.1439</td>\n",
       "      <td>-11.1025</td>\n",
       "      <td>12.4858</td>\n",
       "      <td>-2.2871</td>\n",
       "      <td>19.0422</td>\n",
       "      <td>11.0449</td>\n",
       "      <td>4.1087</td>\n",
       "      <td>4.6974</td>\n",
       "      <td>6.9346</td>\n",
       "      <td>...</td>\n",
       "      <td>13.2070</td>\n",
       "      <td>5.8442</td>\n",
       "      <td>4.7086</td>\n",
       "      <td>5.7141</td>\n",
       "      <td>-1.0410</td>\n",
       "      <td>20.5092</td>\n",
       "      <td>3.2790</td>\n",
       "      <td>-5.5952</td>\n",
       "      <td>7.3176</td>\n",
       "      <td>5.7690</td>\n",
       "      <td>-7.0927</td>\n",
       "      <td>-3.9116</td>\n",
       "      <td>7.2569</td>\n",
       "      <td>-5.8234</td>\n",
       "      <td>25.6820</td>\n",
       "      <td>10.9202</td>\n",
       "      <td>-0.3104</td>\n",
       "      <td>8.8438</td>\n",
       "      <td>-9.7009</td>\n",
       "      <td>2.4013</td>\n",
       "      <td>-4.2935</td>\n",
       "      <td>9.3908</td>\n",
       "      <td>-13.2648</td>\n",
       "      <td>3.1545</td>\n",
       "      <td>23.0866</td>\n",
       "      <td>-5.3000</td>\n",
       "      <td>5.3745</td>\n",
       "      <td>-6.2660</td>\n",
       "      <td>10.1934</td>\n",
       "      <td>-0.8417</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>2.3061</td>\n",
       "      <td>2.8102</td>\n",
       "      <td>13.8463</td>\n",
       "      <td>11.9704</td>\n",
       "      <td>6.4569</td>\n",
       "      <td>14.8372</td>\n",
       "      <td>10.7430</td>\n",
       "      <td>-0.4299</td>\n",
       "      <td>15.9426</td>\n",
       "      <td>13.7257</td>\n",
       "      <td>20.3010</td>\n",
       "      <td>12.5579</td>\n",
       "      <td>6.8202</td>\n",
       "      <td>2.7229</td>\n",
       "      <td>12.1354</td>\n",
       "      <td>13.7367</td>\n",
       "      <td>0.8135</td>\n",
       "      <td>-0.9059</td>\n",
       "      <td>5.9070</td>\n",
       "      <td>2.8407</td>\n",
       "      <td>-15.2398</td>\n",
       "      <td>10.4407</td>\n",
       "      <td>-2.5731</td>\n",
       "      <td>6.1796</td>\n",
       "      <td>10.6093</td>\n",
       "      <td>-5.9158</td>\n",
       "      <td>8.1723</td>\n",
       "      <td>2.8521</td>\n",
       "      <td>...</td>\n",
       "      <td>31.8833</td>\n",
       "      <td>5.9684</td>\n",
       "      <td>7.2084</td>\n",
       "      <td>3.8899</td>\n",
       "      <td>-11.0882</td>\n",
       "      <td>17.2502</td>\n",
       "      <td>2.5881</td>\n",
       "      <td>-2.7018</td>\n",
       "      <td>0.5641</td>\n",
       "      <td>5.3430</td>\n",
       "      <td>-7.1541</td>\n",
       "      <td>-6.1920</td>\n",
       "      <td>18.2366</td>\n",
       "      <td>11.7134</td>\n",
       "      <td>14.7483</td>\n",
       "      <td>8.1013</td>\n",
       "      <td>11.8771</td>\n",
       "      <td>13.9552</td>\n",
       "      <td>-10.4701</td>\n",
       "      <td>5.6961</td>\n",
       "      <td>-3.7546</td>\n",
       "      <td>8.4117</td>\n",
       "      <td>1.8986</td>\n",
       "      <td>7.2601</td>\n",
       "      <td>-0.4639</td>\n",
       "      <td>-0.0498</td>\n",
       "      <td>7.9336</td>\n",
       "      <td>-12.8279</td>\n",
       "      <td>12.4124</td>\n",
       "      <td>1.8489</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>-9.4458</td>\n",
       "      <td>-12.1419</td>\n",
       "      <td>13.8481</td>\n",
       "      <td>7.8895</td>\n",
       "      <td>7.7894</td>\n",
       "      <td>15.0553</td>\n",
       "      <td>8.4871</td>\n",
       "      <td>-3.0680</td>\n",
       "      <td>6.5263</td>\n",
       "      <td>11.3152</td>\n",
       "      <td>21.4246</td>\n",
       "      <td>18.9608</td>\n",
       "      <td>10.1102</td>\n",
       "      <td>2.7142</td>\n",
       "      <td>14.2080</td>\n",
       "      <td>13.5433</td>\n",
       "      <td>3.1736</td>\n",
       "      <td>-3.3423</td>\n",
       "      <td>5.9015</td>\n",
       "      <td>7.9352</td>\n",
       "      <td>-3.1582</td>\n",
       "      <td>9.4668</td>\n",
       "      <td>-0.0083</td>\n",
       "      <td>19.3239</td>\n",
       "      <td>12.4057</td>\n",
       "      <td>0.6329</td>\n",
       "      <td>2.7922</td>\n",
       "      <td>5.8184</td>\n",
       "      <td>...</td>\n",
       "      <td>33.5107</td>\n",
       "      <td>5.6953</td>\n",
       "      <td>5.4663</td>\n",
       "      <td>18.2201</td>\n",
       "      <td>6.5769</td>\n",
       "      <td>21.2607</td>\n",
       "      <td>3.2304</td>\n",
       "      <td>-1.7759</td>\n",
       "      <td>3.1283</td>\n",
       "      <td>5.5518</td>\n",
       "      <td>1.4493</td>\n",
       "      <td>-2.6627</td>\n",
       "      <td>19.8056</td>\n",
       "      <td>2.3705</td>\n",
       "      <td>18.4685</td>\n",
       "      <td>16.3309</td>\n",
       "      <td>-3.3456</td>\n",
       "      <td>13.5261</td>\n",
       "      <td>1.7189</td>\n",
       "      <td>5.1743</td>\n",
       "      <td>-7.6938</td>\n",
       "      <td>9.7685</td>\n",
       "      <td>4.8910</td>\n",
       "      <td>12.2198</td>\n",
       "      <td>11.8503</td>\n",
       "      <td>-7.8931</td>\n",
       "      <td>6.4209</td>\n",
       "      <td>5.9270</td>\n",
       "      <td>16.0201</td>\n",
       "      <td>-0.2829</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1   ...     var_196  var_197  var_198  var_199\n",
       "0  train_0       0   8.9255 -6.7863   ...      7.8784   8.5635  12.7803  -1.0914\n",
       "1  train_1       0  11.5006 -4.1473   ...      8.1267   8.7889  18.3560   1.9518\n",
       "2  train_2       0   8.6093 -2.7457   ...     -6.5213   8.2675  14.7222   0.3965\n",
       "3  train_3       0  11.0604 -2.1518   ...     -2.9275  10.2922  17.9697  -8.9996\n",
       "4  train_4       0   9.8369 -1.4834   ...      3.9267   9.5031  17.9974  -8.8104\n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "cea9f79a8521213571569a0c6ee279be86cd4087"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "856bfa1ebe6f6b0156c6822d1b6f254cc9a59cb7"
   },
   "outputs": [],
   "source": [
    "features = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "target = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "e4a92c12b95ca58c51b0370222e66a7f9cb5f024"
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.33,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.05,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1,\n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 80,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,\n",
    "    'num_threads': 12,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary',\n",
    "    'verbosity': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "34d697c01168ef51bee755a6f62d46915a2d157f"
   },
   "outputs": [],
   "source": [
    "num_round = 100000\n",
    "# check random state 44000\n",
    "folds = StratifiedKFold(n_splits=12, shuffle=False, random_state=12345)\n",
    "oof = np.zeros(len(train_df))\n",
    "predictions = np.zeros(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "c18106c9c64c99f1ec9de38e1d8b2422172e1aa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.899233\tvalid_1's auc: 0.880349\n",
      "[2000]\ttraining's auc: 0.911128\tvalid_1's auc: 0.889263\n",
      "[3000]\ttraining's auc: 0.918754\tvalid_1's auc: 0.894499\n",
      "[4000]\ttraining's auc: 0.924396\tvalid_1's auc: 0.89711\n",
      "[5000]\ttraining's auc: 0.929035\tvalid_1's auc: 0.898704\n",
      "[6000]\ttraining's auc: 0.933285\tvalid_1's auc: 0.89988\n",
      "[7000]\ttraining's auc: 0.937118\tvalid_1's auc: 0.900489\n",
      "[8000]\ttraining's auc: 0.940729\tvalid_1's auc: 0.900885\n",
      "[9000]\ttraining's auc: 0.944081\tvalid_1's auc: 0.900997\n",
      "[10000]\ttraining's auc: 0.947425\tvalid_1's auc: 0.901202\n",
      "[11000]\ttraining's auc: 0.950619\tvalid_1's auc: 0.901436\n",
      "[12000]\ttraining's auc: 0.953713\tvalid_1's auc: 0.901173\n",
      "[13000]\ttraining's auc: 0.95671\tvalid_1's auc: 0.901372\n",
      "[14000]\ttraining's auc: 0.959523\tvalid_1's auc: 0.901367\n",
      "[15000]\ttraining's auc: 0.962183\tvalid_1's auc: 0.901156\n",
      "[16000]\ttraining's auc: 0.96474\tvalid_1's auc: 0.901018\n",
      "Early stopping, best iteration is:\n",
      "[13764]\ttraining's auc: 0.958881\tvalid_1's auc: 0.901526\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.899312\tvalid_1's auc: 0.883923\n",
      "[2000]\ttraining's auc: 0.911268\tvalid_1's auc: 0.891012\n",
      "[3000]\ttraining's auc: 0.918918\tvalid_1's auc: 0.894772\n",
      "[4000]\ttraining's auc: 0.924578\tvalid_1's auc: 0.896674\n",
      "[5000]\ttraining's auc: 0.929167\tvalid_1's auc: 0.89777\n",
      "[6000]\ttraining's auc: 0.933386\tvalid_1's auc: 0.898384\n",
      "[7000]\ttraining's auc: 0.937223\tvalid_1's auc: 0.898475\n",
      "[8000]\ttraining's auc: 0.940795\tvalid_1's auc: 0.898785\n",
      "[9000]\ttraining's auc: 0.944193\tvalid_1's auc: 0.89893\n",
      "[10000]\ttraining's auc: 0.947551\tvalid_1's auc: 0.899388\n",
      "[11000]\ttraining's auc: 0.950719\tvalid_1's auc: 0.899442\n",
      "[12000]\ttraining's auc: 0.953771\tvalid_1's auc: 0.899435\n",
      "[13000]\ttraining's auc: 0.956691\tvalid_1's auc: 0.899268\n",
      "Early stopping, best iteration is:\n",
      "[10558]\ttraining's auc: 0.949343\tvalid_1's auc: 0.899575\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.899844\tvalid_1's auc: 0.873028\n",
      "[2000]\ttraining's auc: 0.912019\tvalid_1's auc: 0.882847\n",
      "[3000]\ttraining's auc: 0.919488\tvalid_1's auc: 0.886973\n",
      "[4000]\ttraining's auc: 0.92502\tvalid_1's auc: 0.889183\n",
      "[5000]\ttraining's auc: 0.929692\tvalid_1's auc: 0.890099\n",
      "[6000]\ttraining's auc: 0.933867\tvalid_1's auc: 0.891067\n",
      "[7000]\ttraining's auc: 0.937617\tvalid_1's auc: 0.891038\n",
      "[8000]\ttraining's auc: 0.941202\tvalid_1's auc: 0.891174\n",
      "[9000]\ttraining's auc: 0.944607\tvalid_1's auc: 0.891152\n",
      "[10000]\ttraining's auc: 0.947912\tvalid_1's auc: 0.891145\n",
      "Early stopping, best iteration is:\n",
      "[7586]\ttraining's auc: 0.939764\tvalid_1's auc: 0.891283\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.898676\tvalid_1's auc: 0.886912\n",
      "[2000]\ttraining's auc: 0.910717\tvalid_1's auc: 0.897061\n",
      "[3000]\ttraining's auc: 0.918293\tvalid_1's auc: 0.90134\n",
      "[4000]\ttraining's auc: 0.923994\tvalid_1's auc: 0.90359\n",
      "[5000]\ttraining's auc: 0.928687\tvalid_1's auc: 0.904892\n",
      "[6000]\ttraining's auc: 0.932879\tvalid_1's auc: 0.90547\n",
      "[7000]\ttraining's auc: 0.936714\tvalid_1's auc: 0.905658\n",
      "[8000]\ttraining's auc: 0.940379\tvalid_1's auc: 0.905458\n",
      "[9000]\ttraining's auc: 0.943849\tvalid_1's auc: 0.905327\n",
      "Early stopping, best iteration is:\n",
      "[6881]\ttraining's auc: 0.936286\tvalid_1's auc: 0.905672\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.899331\tvalid_1's auc: 0.875429\n",
      "[2000]\ttraining's auc: 0.911453\tvalid_1's auc: 0.884042\n",
      "[3000]\ttraining's auc: 0.919137\tvalid_1's auc: 0.888224\n",
      "[4000]\ttraining's auc: 0.924785\tvalid_1's auc: 0.890768\n",
      "[5000]\ttraining's auc: 0.929441\tvalid_1's auc: 0.891981\n",
      "[6000]\ttraining's auc: 0.933563\tvalid_1's auc: 0.89273\n",
      "[7000]\ttraining's auc: 0.937352\tvalid_1's auc: 0.893067\n",
      "[8000]\ttraining's auc: 0.940915\tvalid_1's auc: 0.89337\n",
      "[9000]\ttraining's auc: 0.944358\tvalid_1's auc: 0.893563\n",
      "[10000]\ttraining's auc: 0.947676\tvalid_1's auc: 0.893753\n",
      "[11000]\ttraining's auc: 0.950838\tvalid_1's auc: 0.893647\n",
      "[12000]\ttraining's auc: 0.953836\tvalid_1's auc: 0.893372\n",
      "Early stopping, best iteration is:\n",
      "[10313]\ttraining's auc: 0.948688\tvalid_1's auc: 0.89389\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.899373\tvalid_1's auc: 0.88311\n",
      "[2000]\ttraining's auc: 0.911168\tvalid_1's auc: 0.892636\n",
      "[3000]\ttraining's auc: 0.918719\tvalid_1's auc: 0.896519\n",
      "[4000]\ttraining's auc: 0.924449\tvalid_1's auc: 0.898584\n",
      "[5000]\ttraining's auc: 0.929058\tvalid_1's auc: 0.899516\n",
      "[6000]\ttraining's auc: 0.933182\tvalid_1's auc: 0.899747\n",
      "[7000]\ttraining's auc: 0.936995\tvalid_1's auc: 0.899683\n",
      "[8000]\ttraining's auc: 0.940625\tvalid_1's auc: 0.899931\n",
      "[9000]\ttraining's auc: 0.944054\tvalid_1's auc: 0.900007\n",
      "[10000]\ttraining's auc: 0.947365\tvalid_1's auc: 0.899662\n",
      "[11000]\ttraining's auc: 0.950543\tvalid_1's auc: 0.899545\n",
      "Early stopping, best iteration is:\n",
      "[9002]\ttraining's auc: 0.944061\tvalid_1's auc: 0.90001\n",
      "Fold 6\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.89882\tvalid_1's auc: 0.884637\n",
      "[2000]\ttraining's auc: 0.910853\tvalid_1's auc: 0.893323\n",
      "[3000]\ttraining's auc: 0.918506\tvalid_1's auc: 0.897193\n",
      "[4000]\ttraining's auc: 0.924179\tvalid_1's auc: 0.899615\n",
      "[5000]\ttraining's auc: 0.928948\tvalid_1's auc: 0.900762\n",
      "[6000]\ttraining's auc: 0.933152\tvalid_1's auc: 0.901394\n",
      "[7000]\ttraining's auc: 0.936965\tvalid_1's auc: 0.901899\n",
      "[8000]\ttraining's auc: 0.940666\tvalid_1's auc: 0.901913\n",
      "[9000]\ttraining's auc: 0.944108\tvalid_1's auc: 0.901958\n",
      "[10000]\ttraining's auc: 0.947442\tvalid_1's auc: 0.901903\n",
      "[11000]\ttraining's auc: 0.950653\tvalid_1's auc: 0.901578\n",
      "Early stopping, best iteration is:\n",
      "[8764]\ttraining's auc: 0.943312\tvalid_1's auc: 0.902056\n",
      "Fold 7\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.898828\tvalid_1's auc: 0.888121\n",
      "[2000]\ttraining's auc: 0.910866\tvalid_1's auc: 0.896418\n",
      "[3000]\ttraining's auc: 0.918402\tvalid_1's auc: 0.900263\n",
      "[4000]\ttraining's auc: 0.92416\tvalid_1's auc: 0.902104\n",
      "[5000]\ttraining's auc: 0.928855\tvalid_1's auc: 0.902638\n",
      "[6000]\ttraining's auc: 0.933009\tvalid_1's auc: 0.902885\n",
      "[7000]\ttraining's auc: 0.936816\tvalid_1's auc: 0.903261\n",
      "[8000]\ttraining's auc: 0.940502\tvalid_1's auc: 0.90333\n",
      "[9000]\ttraining's auc: 0.943992\tvalid_1's auc: 0.90333\n",
      "[10000]\ttraining's auc: 0.947315\tvalid_1's auc: 0.90323\n",
      "[11000]\ttraining's auc: 0.950502\tvalid_1's auc: 0.903065\n",
      "Early stopping, best iteration is:\n",
      "[8624]\ttraining's auc: 0.942698\tvalid_1's auc: 0.903439\n",
      "Fold 8\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.899706\tvalid_1's auc: 0.880166\n",
      "[2000]\ttraining's auc: 0.911494\tvalid_1's auc: 0.888323\n",
      "[3000]\ttraining's auc: 0.918977\tvalid_1's auc: 0.892776\n",
      "[4000]\ttraining's auc: 0.924714\tvalid_1's auc: 0.89507\n",
      "[5000]\ttraining's auc: 0.929392\tvalid_1's auc: 0.896788\n",
      "[6000]\ttraining's auc: 0.933426\tvalid_1's auc: 0.897707\n",
      "[7000]\ttraining's auc: 0.937265\tvalid_1's auc: 0.898094\n",
      "[8000]\ttraining's auc: 0.940922\tvalid_1's auc: 0.898268\n",
      "[9000]\ttraining's auc: 0.944314\tvalid_1's auc: 0.898346\n",
      "[10000]\ttraining's auc: 0.947698\tvalid_1's auc: 0.898278\n",
      "[11000]\ttraining's auc: 0.950854\tvalid_1's auc: 0.898394\n",
      "[12000]\ttraining's auc: 0.953887\tvalid_1's auc: 0.898353\n",
      "[13000]\ttraining's auc: 0.956799\tvalid_1's auc: 0.898307\n",
      "Early stopping, best iteration is:\n",
      "[10768]\ttraining's auc: 0.950131\tvalid_1's auc: 0.898467\n",
      "Fold 9\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.898851\tvalid_1's auc: 0.887869\n",
      "[2000]\ttraining's auc: 0.910804\tvalid_1's auc: 0.895836\n",
      "[3000]\ttraining's auc: 0.918422\tvalid_1's auc: 0.900279\n",
      "[4000]\ttraining's auc: 0.924057\tvalid_1's auc: 0.902407\n",
      "[5000]\ttraining's auc: 0.928824\tvalid_1's auc: 0.903146\n",
      "[6000]\ttraining's auc: 0.933039\tvalid_1's auc: 0.903984\n",
      "[7000]\ttraining's auc: 0.936909\tvalid_1's auc: 0.904167\n",
      "[8000]\ttraining's auc: 0.940545\tvalid_1's auc: 0.903896\n",
      "[9000]\ttraining's auc: 0.943974\tvalid_1's auc: 0.903971\n",
      "Early stopping, best iteration is:\n",
      "[6867]\ttraining's auc: 0.936428\tvalid_1's auc: 0.904225\n",
      "Fold 10\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.898796\tvalid_1's auc: 0.888631\n",
      "[2000]\ttraining's auc: 0.910624\tvalid_1's auc: 0.897079\n",
      "[3000]\ttraining's auc: 0.91805\tvalid_1's auc: 0.90147\n",
      "[4000]\ttraining's auc: 0.923683\tvalid_1's auc: 0.903849\n",
      "[5000]\ttraining's auc: 0.928441\tvalid_1's auc: 0.905223\n",
      "[6000]\ttraining's auc: 0.932667\tvalid_1's auc: 0.905823\n",
      "[7000]\ttraining's auc: 0.936592\tvalid_1's auc: 0.9064\n",
      "[8000]\ttraining's auc: 0.940238\tvalid_1's auc: 0.906815\n",
      "[9000]\ttraining's auc: 0.943656\tvalid_1's auc: 0.906861\n",
      "[10000]\ttraining's auc: 0.947008\tvalid_1's auc: 0.906748\n",
      "[11000]\ttraining's auc: 0.950154\tvalid_1's auc: 0.90663\n",
      "Early stopping, best iteration is:\n",
      "[8754]\ttraining's auc: 0.942827\tvalid_1's auc: 0.906908\n",
      "Fold 11\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.899488\tvalid_1's auc: 0.883561\n",
      "[2000]\ttraining's auc: 0.911582\tvalid_1's auc: 0.891063\n",
      "[3000]\ttraining's auc: 0.919033\tvalid_1's auc: 0.895214\n",
      "[4000]\ttraining's auc: 0.924742\tvalid_1's auc: 0.897164\n",
      "[5000]\ttraining's auc: 0.929427\tvalid_1's auc: 0.898374\n",
      "[6000]\ttraining's auc: 0.933663\tvalid_1's auc: 0.89924\n",
      "[7000]\ttraining's auc: 0.93749\tvalid_1's auc: 0.899629\n",
      "[8000]\ttraining's auc: 0.941085\tvalid_1's auc: 0.899849\n",
      "[9000]\ttraining's auc: 0.944489\tvalid_1's auc: 0.899895\n",
      "[10000]\ttraining's auc: 0.947873\tvalid_1's auc: 0.899572\n",
      "[11000]\ttraining's auc: 0.950995\tvalid_1's auc: 0.899623\n",
      "Early stopping, best iteration is:\n",
      "[8961]\ttraining's auc: 0.944367\tvalid_1's auc: 0.89999\n",
      "CV score: 0.90033 \n"
     ]
    }
   ],
   "source": [
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 2500)\n",
    "    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "bbd4b5208debf786527aafb6ae0e3373997ce914"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"ID_code\": test_df.ID_code.values})\n",
    "submission[\"target\"] = predictions\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "da8fedbf508e8b212c7e374a456240611b2cc345"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0.105329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0.200174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0.176622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0.219697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0.042938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    target\n",
       "0  test_0  0.105329\n",
       "1  test_1  0.200174\n",
       "2  test_2  0.176622\n",
       "3  test_3  0.219697\n",
       "4  test_4  0.042938"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "932dca12a72e86cb632bfc588dce2b596e1c90ee"
   },
   "outputs": [],
   "source": [
    "num_round = 100\n",
    "# check random state 1\n",
    "folds = StratifiedKFold(n_splits=10, shuffle=False, random_state=1)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(features.values, target.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(features.iloc[trn_idx], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(features.iloc[val_idx], label=target.iloc[val_idx])\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 25)\n",
    "    oof[val_idx] = clf.predict(features.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "    predictions += clf.predict(test1, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
