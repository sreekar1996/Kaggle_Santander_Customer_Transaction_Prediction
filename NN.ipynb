{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sreekar chidurala\\Anaconda3\\envs\\sreekar\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400000, 202)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.concat([train, test])\n",
    "#Saving the list of original features in a new list `original_features`.\n",
    "original_features = merged.columns\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = features = merged.columns.values[0:200]\n",
    "for df in [merged]:\n",
    "    df['sum'] = df[idx].sum(axis=1)  \n",
    "    df['max'] = df[idx].max(axis=1)\n",
    "    df['mean'] = df[idx].mean(axis=1)\n",
    "    df['std'] = df[idx].std(axis=1)\n",
    "    df['skew'] = df[idx].skew(axis=1)\n",
    "    df['kurt'] = df[idx].kurtosis(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"new\"]=merged[\"var_108\"]*merged[\"var_63\"]\n",
    "merged[\"log_73\"]=np.log(merged[\"var_73\"]+10)\n",
    "merged[\"log_1\"]=np.log(merged[\"var_1\"]+17)\n",
    "merged[\"log_1*73\"]=merged[\"log_73\"]*merged[\"log_1\"]\n",
    "merged[\"var_2_sq\"]=merged[\"var_2\"]*merged[\"var_2\"]\n",
    "merged[\"var_10_100_101\"]=merged[\"var_10\"]-merged[\"var_100\"]-merged[\"var_101\"]\n",
    "merged[\"log_81\"]=np.log(merged[\"var_81\"]+10)\n",
    "merged[\"log_1*81\"]=merged[\"log_81\"]*merged[\"log_1\"]\n",
    "merged[\"var_12_110_101\"]=merged[\"var_12\"]-merged[\"var_110\"]-merged[\"var_101\"]\n",
    "merged[\"var_166_80_174\"]=merged[\"var_166\"]-merged[\"var_80\"]-merged[\"var_174\"]\n",
    "merged[\"new1\"]=merged[\"var_146\"]*merged[\"var_6\"]\n",
    "merged[\"new2\"]=merged[\"var_146\"]*merged[\"var_80\"]*merged[\"var_21\"]\n",
    "merged[\"log_13\"]=np.log(merged[\"var_13\"]+10)\n",
    "merged[\"var_10_100_21_13\"]=merged[\"var_10\"]-merged[\"var_100\"]-merged[\"var_21\"]+merged[\"log_13\"]\n",
    "merged[\"var_6_cube\"]=merged[\"var_6\"]*merged[\"var_6\"]*merged[\"var_80\"]\n",
    "merged[\"var_10_109_21\"]=merged[\"var_16\"]-merged[\"var_156\"]-merged[\"var_98\"]\n",
    "merged[\"var_134_100_101\"]=merged[\"var_17\"]+merged[\"var_166\"]-merged[\"var_8\"]\n",
    "merged[\"log_17\"]=np.log(merged[\"var_17\"]+40)\n",
    "merged[\"var_134_100_101_log17\"]=merged[\"var_17\"]+merged[\"var_166\"]-merged[\"var_8\"] * merged[\"log_17\"]\n",
    "merged[\"new5\"]=merged[\"var_145\"]*merged[\"var_88\"]-merged[\"var_20\"]\n",
    "merged[\"var_10_100_201_13\"]=merged[\"var_101\"]*merged[\"var_109\"]-merged[\"var_89\"]+merged[\"var_23\"]\n",
    "merged[\"new9\"]=merged[\"var_146\"]*merged[\"var_6\"]-merged[\"var_10_100_201_13\"]\n",
    "merged[\"var_10_100_2455\"]=merged[\"var_105\"]+merged[\"var_187\"]*merged[\"var_25\"]-merged[\"new9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged=merged.drop(['var_0', 'var_1', 'var_101', 'var_102', 'var_104', 'var_105',\n",
    "       'var_106', 'var_107', 'var_108', 'var_109', 'var_11', 'var_110',\n",
    "     \n",
    "       'var_94', 'var_95', 'var_97', 'var_98', 'var_99'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 214)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_10</th>\n",
       "      <th>var_100</th>\n",
       "      <th>var_103</th>\n",
       "      <th>var_111</th>\n",
       "      <th>var_112</th>\n",
       "      <th>var_113</th>\n",
       "      <th>var_114</th>\n",
       "      <th>var_115</th>\n",
       "      <th>...</th>\n",
       "      <th>var_10_100_21_13</th>\n",
       "      <th>var_6_cube</th>\n",
       "      <th>var_10_109_21</th>\n",
       "      <th>var_134_100_101</th>\n",
       "      <th>log_17</th>\n",
       "      <th>var_134_100_101_log17</th>\n",
       "      <th>new5</th>\n",
       "      <th>var_10_100_201_13</th>\n",
       "      <th>new9</th>\n",
       "      <th>var_10_100_2455</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9252</td>\n",
       "      <td>9.4763</td>\n",
       "      <td>1.4403</td>\n",
       "      <td>6.7602</td>\n",
       "      <td>3.9141</td>\n",
       "      <td>-0.4851</td>\n",
       "      <td>2.5240</td>\n",
       "      <td>1.5093</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.411755</td>\n",
       "      <td>357.561031</td>\n",
       "      <td>-8.6005</td>\n",
       "      <td>0.3811</td>\n",
       "      <td>3.489230</td>\n",
       "      <td>12.628110</td>\n",
       "      <td>56.406809</td>\n",
       "      <td>328.450910</td>\n",
       "      <td>-269.248537</td>\n",
       "      <td>10.460110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4032</td>\n",
       "      <td>-13.6950</td>\n",
       "      <td>1.7093</td>\n",
       "      <td>7.1051</td>\n",
       "      <td>5.3523</td>\n",
       "      <td>8.5426</td>\n",
       "      <td>3.6159</td>\n",
       "      <td>4.1569</td>\n",
       "      <td>...</td>\n",
       "      <td>13.464184</td>\n",
       "      <td>80.443096</td>\n",
       "      <td>-0.3088</td>\n",
       "      <td>-15.5314</td>\n",
       "      <td>3.195202</td>\n",
       "      <td>-22.439261</td>\n",
       "      <td>84.078682</td>\n",
       "      <td>101.151203</td>\n",
       "      <td>-50.996243</td>\n",
       "      <td>-167.691080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.3249</td>\n",
       "      <td>-0.3939</td>\n",
       "      <td>1.3854</td>\n",
       "      <td>5.7033</td>\n",
       "      <td>4.5255</td>\n",
       "      <td>2.1929</td>\n",
       "      <td>3.1290</td>\n",
       "      <td>2.9044</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.217277</td>\n",
       "      <td>360.201875</td>\n",
       "      <td>-8.5561</td>\n",
       "      <td>6.4588</td>\n",
       "      <td>3.644418</td>\n",
       "      <td>19.467486</td>\n",
       "      <td>34.209107</td>\n",
       "      <td>258.906626</td>\n",
       "      <td>-179.111398</td>\n",
       "      <td>100.288790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3061</td>\n",
       "      <td>-19.8592</td>\n",
       "      <td>1.3512</td>\n",
       "      <td>6.9750</td>\n",
       "      <td>1.6480</td>\n",
       "      <td>11.6896</td>\n",
       "      <td>2.5762</td>\n",
       "      <td>-2.5459</td>\n",
       "      <td>...</td>\n",
       "      <td>12.697096</td>\n",
       "      <td>26.761023</td>\n",
       "      <td>-4.1414</td>\n",
       "      <td>8.0191</td>\n",
       "      <td>3.678074</td>\n",
       "      <td>23.715023</td>\n",
       "      <td>-6.998491</td>\n",
       "      <td>319.931217</td>\n",
       "      <td>-258.585322</td>\n",
       "      <td>86.655808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.4458</td>\n",
       "      <td>-22.9264</td>\n",
       "      <td>1.6940</td>\n",
       "      <td>5.9654</td>\n",
       "      <td>1.0719</td>\n",
       "      <td>7.9923</td>\n",
       "      <td>2.9138</td>\n",
       "      <td>-3.6135</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.595986</td>\n",
       "      <td>104.449981</td>\n",
       "      <td>-6.1994</td>\n",
       "      <td>-6.1030</td>\n",
       "      <td>3.609078</td>\n",
       "      <td>-22.449920</td>\n",
       "      <td>51.879932</td>\n",
       "      <td>348.289119</td>\n",
       "      <td>-279.575356</td>\n",
       "      <td>365.039895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target  var_10  var_100  var_103  var_111  var_112  var_113  \\\n",
       "0  train_0     0.0  2.9252   9.4763   1.4403   6.7602   3.9141  -0.4851   \n",
       "1  train_1     0.0 -0.4032 -13.6950   1.7093   7.1051   5.3523   8.5426   \n",
       "2  train_2     0.0 -0.3249  -0.3939   1.3854   5.7033   4.5255   2.1929   \n",
       "3  train_3     0.0  2.3061 -19.8592   1.3512   6.9750   1.6480  11.6896   \n",
       "4  train_4     0.0 -9.4458 -22.9264   1.6940   5.9654   1.0719   7.9923   \n",
       "\n",
       "   var_114  var_115       ...         var_10_100_21_13  var_6_cube  \\\n",
       "0   2.5240   1.5093       ...               -20.411755  357.561031   \n",
       "1   3.6159   4.1569       ...                13.464184   80.443096   \n",
       "2   3.1290   2.9044       ...               -15.217277  360.201875   \n",
       "3   2.5762  -2.5459       ...                12.697096   26.761023   \n",
       "4   2.9138  -3.6135       ...                -2.595986  104.449981   \n",
       "\n",
       "   var_10_109_21  var_134_100_101    log_17  var_134_100_101_log17       new5  \\\n",
       "0        -8.6005           0.3811  3.489230              12.628110  56.406809   \n",
       "1        -0.3088         -15.5314  3.195202             -22.439261  84.078682   \n",
       "2        -8.5561           6.4588  3.644418              19.467486  34.209107   \n",
       "3        -4.1414           8.0191  3.678074              23.715023  -6.998491   \n",
       "4        -6.1994          -6.1030  3.609078             -22.449920  51.879932   \n",
       "\n",
       "   var_10_100_201_13        new9  var_10_100_2455  \n",
       "0         328.450910 -269.248537        10.460110  \n",
       "1         101.151203  -50.996243      -167.691080  \n",
       "2         258.906626 -179.111398       100.288790  \n",
       "3         319.931217 -258.585322        86.655808  \n",
       "4         348.289119 -279.575356       365.039895  \n",
       "\n",
       "[5 rows x 214 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = merged.iloc[:len(train)]\n",
    "X = train\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_10</th>\n",
       "      <th>var_100</th>\n",
       "      <th>var_103</th>\n",
       "      <th>var_111</th>\n",
       "      <th>var_112</th>\n",
       "      <th>var_113</th>\n",
       "      <th>var_114</th>\n",
       "      <th>var_115</th>\n",
       "      <th>...</th>\n",
       "      <th>var_10_100_21_13</th>\n",
       "      <th>var_6_cube</th>\n",
       "      <th>var_10_109_21</th>\n",
       "      <th>var_134_100_101</th>\n",
       "      <th>log_17</th>\n",
       "      <th>var_134_100_101_log17</th>\n",
       "      <th>new5</th>\n",
       "      <th>var_10_100_201_13</th>\n",
       "      <th>new9</th>\n",
       "      <th>var_10_100_2455</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0248</td>\n",
       "      <td>-9.2198</td>\n",
       "      <td>1.4918</td>\n",
       "      <td>6.0426</td>\n",
       "      <td>4.4243</td>\n",
       "      <td>14.1799</td>\n",
       "      <td>2.0921</td>\n",
       "      <td>1.5493</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.274819</td>\n",
       "      <td>324.635642</td>\n",
       "      <td>-6.3348</td>\n",
       "      <td>-18.6725</td>\n",
       "      <td>3.040137</td>\n",
       "      <td>-23.025540</td>\n",
       "      <td>36.061478</td>\n",
       "      <td>256.088869</td>\n",
       "      <td>-187.773140</td>\n",
       "      <td>-141.533264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.3809</td>\n",
       "      <td>-1.7257</td>\n",
       "      <td>1.6570</td>\n",
       "      <td>5.5689</td>\n",
       "      <td>3.6609</td>\n",
       "      <td>8.9725</td>\n",
       "      <td>4.1159</td>\n",
       "      <td>1.0693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263050</td>\n",
       "      <td>71.644997</td>\n",
       "      <td>-9.8481</td>\n",
       "      <td>12.2880</td>\n",
       "      <td>3.798998</td>\n",
       "      <td>24.640256</td>\n",
       "      <td>-53.542356</td>\n",
       "      <td>274.060938</td>\n",
       "      <td>-221.302756</td>\n",
       "      <td>106.456720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.7057</td>\n",
       "      <td>-3.5065</td>\n",
       "      <td>1.3935</td>\n",
       "      <td>8.1036</td>\n",
       "      <td>1.2057</td>\n",
       "      <td>8.9156</td>\n",
       "      <td>0.9777</td>\n",
       "      <td>2.3797</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.942806</td>\n",
       "      <td>387.428209</td>\n",
       "      <td>-4.1631</td>\n",
       "      <td>4.2551</td>\n",
       "      <td>3.753123</td>\n",
       "      <td>0.061267</td>\n",
       "      <td>-13.281539</td>\n",
       "      <td>283.619765</td>\n",
       "      <td>-226.471129</td>\n",
       "      <td>202.655705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>1.7021</td>\n",
       "      <td>1.5173</td>\n",
       "      <td>6.0369</td>\n",
       "      <td>5.0227</td>\n",
       "      <td>12.6600</td>\n",
       "      <td>2.1278</td>\n",
       "      <td>4.0592</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.088257</td>\n",
       "      <td>429.307231</td>\n",
       "      <td>-4.9757</td>\n",
       "      <td>-16.0848</td>\n",
       "      <td>3.204744</td>\n",
       "      <td>-23.526915</td>\n",
       "      <td>4.995591</td>\n",
       "      <td>62.342436</td>\n",
       "      <td>-19.385323</td>\n",
       "      <td>-257.450069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.1025</td>\n",
       "      <td>-14.3858</td>\n",
       "      <td>1.4375</td>\n",
       "      <td>6.8699</td>\n",
       "      <td>2.7253</td>\n",
       "      <td>12.6458</td>\n",
       "      <td>3.2376</td>\n",
       "      <td>3.4218</td>\n",
       "      <td>...</td>\n",
       "      <td>6.125111</td>\n",
       "      <td>555.848136</td>\n",
       "      <td>-2.8154</td>\n",
       "      <td>3.3938</td>\n",
       "      <td>3.764636</td>\n",
       "      <td>-4.869697</td>\n",
       "      <td>-7.403807</td>\n",
       "      <td>289.122359</td>\n",
       "      <td>-200.410504</td>\n",
       "      <td>-139.802826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code  target  var_10  var_100  var_103  var_111  var_112  var_113  \\\n",
       "0  test_0     NaN -2.0248  -9.2198   1.4918   6.0426   4.4243  14.1799   \n",
       "1  test_1     NaN -1.3809  -1.7257   1.6570   5.5689   3.6609   8.9725   \n",
       "2  test_2     NaN -4.7057  -3.5065   1.3935   8.1036   1.2057   8.9156   \n",
       "3  test_3     NaN  0.0095   1.7021   1.5173   6.0369   5.0227  12.6600   \n",
       "4  test_4     NaN  5.1025 -14.3858   1.4375   6.8699   2.7253  12.6458   \n",
       "\n",
       "   var_114  var_115       ...         var_10_100_21_13  var_6_cube  \\\n",
       "0   2.0921   1.5493       ...                -9.274819  324.635642   \n",
       "1   4.1159   1.0693       ...                -0.263050   71.644997   \n",
       "2   0.9777   2.3797       ...               -10.942806  387.428209   \n",
       "3   2.1278   4.0592       ...               -11.088257  429.307231   \n",
       "4   3.2376   3.4218       ...                 6.125111  555.848136   \n",
       "\n",
       "   var_10_109_21  var_134_100_101    log_17  var_134_100_101_log17       new5  \\\n",
       "0        -6.3348         -18.6725  3.040137             -23.025540  36.061478   \n",
       "1        -9.8481          12.2880  3.798998              24.640256 -53.542356   \n",
       "2        -4.1631           4.2551  3.753123               0.061267 -13.281539   \n",
       "3        -4.9757         -16.0848  3.204744             -23.526915   4.995591   \n",
       "4        -2.8154           3.3938  3.764636              -4.869697  -7.403807   \n",
       "\n",
       "   var_10_100_201_13        new9  var_10_100_2455  \n",
       "0         256.088869 -187.773140      -141.533264  \n",
       "1         274.060938 -221.302756       106.456720  \n",
       "2         283.619765 -226.471129       202.655705  \n",
       "3          62.342436  -19.385323      -257.450069  \n",
       "4         289.122359 -200.410504      -139.802826  \n",
       "\n",
       "[5 rows x 214 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = merged.iloc[len(train):]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2=test.drop([\"target\",\"ID_code\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=train.drop([\"ID_code\",\"target\"],1)\n",
    "target=train[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(features)\n",
    "features = scaler.transform(features)\n",
    "test2 = scaler.transform(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=pd.DataFrame(features)\n",
    "test2=pd.DataFrame(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.33,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.05,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1,\n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 80,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,\n",
    "    'num_threads': 12,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary',\n",
    "    'verbosity': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu', input_dim = features.shape[1]))\n",
    "classifier.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy',auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "200000/200000 [==============================] - 33s 163us/step - loss: 0.2665 - acc: 0.9051 - auc: 0.7669\n",
      "Epoch 2/150\n",
      "200000/200000 [==============================] - 32s 162us/step - loss: 0.2543 - acc: 0.9077 - auc: 0.8051\n",
      "Epoch 3/150\n",
      "200000/200000 [==============================] - 32s 162us/step - loss: 0.2509 - acc: 0.9084 - auc: 0.8141\n",
      "Epoch 4/150\n",
      "200000/200000 [==============================] - 32s 161us/step - loss: 0.2493 - acc: 0.9092 - auc: 0.8189\n",
      "Epoch 5/150\n",
      "200000/200000 [==============================] - 33s 163us/step - loss: 0.2483 - acc: 0.9094 - auc: 0.8220\n",
      "Epoch 6/150\n",
      "200000/200000 [==============================] - 33s 164us/step - loss: 0.2478 - acc: 0.9095 - auc: 0.8242\n",
      "Epoch 7/150\n",
      "200000/200000 [==============================] - 32s 161us/step - loss: 0.2471 - acc: 0.9098 - auc: 0.8258\n",
      "Epoch 8/150\n",
      "200000/200000 [==============================] - 34s 170us/step - loss: 0.2460 - acc: 0.9103 - auc: 0.8271\n",
      "Epoch 9/150\n",
      "200000/200000 [==============================] - 33s 164us/step - loss: 0.2458 - acc: 0.9102 - auc: 0.8285\n",
      "Epoch 10/150\n",
      "200000/200000 [==============================] - 33s 163us/step - loss: 0.2455 - acc: 0.9103 - auc: 0.8294\n",
      "Epoch 11/150\n",
      "200000/200000 [==============================] - 33s 164us/step - loss: 0.2454 - acc: 0.9101 - auc: 0.8303\n",
      "Epoch 12/150\n",
      "200000/200000 [==============================] - 34s 168us/step - loss: 0.2449 - acc: 0.9103 - auc: 0.8310\n",
      "Epoch 13/150\n",
      "200000/200000 [==============================] - 33s 165us/step - loss: 0.2443 - acc: 0.9104 - auc: 0.8316\n",
      "Epoch 14/150\n",
      "200000/200000 [==============================] - 34s 170us/step - loss: 0.2439 - acc: 0.9106 - auc: 0.8323\n",
      "Epoch 15/150\n",
      "200000/200000 [==============================] - 34s 169us/step - loss: 0.2439 - acc: 0.9107 - auc: 0.8329\n",
      "Epoch 16/150\n",
      "200000/200000 [==============================] - 33s 165us/step - loss: 0.2435 - acc: 0.9106 - auc: 0.8334\n",
      "Epoch 17/150\n",
      "200000/200000 [==============================] - 36s 179us/step - loss: 0.2430 - acc: 0.9110 - auc: 0.8339\n",
      "Epoch 18/150\n",
      "200000/200000 [==============================] - 33s 166us/step - loss: 0.2430 - acc: 0.9108 - auc: 0.8344\n",
      "Epoch 19/150\n",
      "200000/200000 [==============================] - 33s 167us/step - loss: 0.2429 - acc: 0.9106 - auc: 0.8348\n",
      "Epoch 20/150\n",
      "200000/200000 [==============================] - 35s 174us/step - loss: 0.2429 - acc: 0.9109 - auc: 0.8352\n",
      "Epoch 21/150\n",
      "200000/200000 [==============================] - 33s 166us/step - loss: 0.2425 - acc: 0.9110 - auc: 0.8355\n",
      "Epoch 22/150\n",
      "200000/200000 [==============================] - 37s 185us/step - loss: 0.2423 - acc: 0.9109 - auc: 0.8359\n",
      "Epoch 23/150\n",
      "200000/200000 [==============================] - 34s 172us/step - loss: 0.2423 - acc: 0.9111 - auc: 0.8362\n",
      "Epoch 24/150\n",
      "200000/200000 [==============================] - 35s 173us/step - loss: 0.2422 - acc: 0.9110 - auc: 0.8365\n",
      "Epoch 25/150\n",
      "200000/200000 [==============================] - 33s 166us/step - loss: 0.2419 - acc: 0.9109 - auc: 0.8368\n",
      "Epoch 26/150\n",
      "200000/200000 [==============================] - 35s 175us/step - loss: 0.2419 - acc: 0.9113 - auc: 0.8371\n",
      "Epoch 27/150\n",
      "200000/200000 [==============================] - 35s 173us/step - loss: 0.2413 - acc: 0.9116 - auc: 0.83730s - loss: 0.2412 - acc: 0.9116 - auc:\n",
      "Epoch 28/150\n",
      "200000/200000 [==============================] - 34s 170us/step - loss: 0.2415 - acc: 0.9114 - auc: 0.8376\n",
      "Epoch 29/150\n",
      "200000/200000 [==============================] - 33s 167us/step - loss: 0.2413 - acc: 0.9112 - auc: 0.8378\n",
      "Epoch 30/150\n",
      "200000/200000 [==============================] - 33s 165us/step - loss: 0.2411 - acc: 0.9110 - auc: 0.8381\n",
      "Epoch 31/150\n",
      "200000/200000 [==============================] - 33s 166us/step - loss: 0.2412 - acc: 0.9113 - auc: 0.8383\n",
      "Epoch 32/150\n",
      "200000/200000 [==============================] - 33s 167us/step - loss: 0.2410 - acc: 0.9112 - auc: 0.8385\n",
      "Epoch 33/150\n",
      "200000/200000 [==============================] - 34s 168us/step - loss: 0.2408 - acc: 0.9114 - auc: 0.8387\n",
      "Epoch 34/150\n",
      "200000/200000 [==============================] - 33s 167us/step - loss: 0.2405 - acc: 0.9116 - auc: 0.8390\n",
      "Epoch 35/150\n",
      "200000/200000 [==============================] - 34s 168us/step - loss: 0.2405 - acc: 0.9115 - auc: 0.8392\n",
      "Epoch 36/150\n",
      "200000/200000 [==============================] - 34s 169us/step - loss: 0.2404 - acc: 0.9116 - auc: 0.8394\n",
      "Epoch 37/150\n",
      "200000/200000 [==============================] - 34s 169us/step - loss: 0.2402 - acc: 0.9115 - auc: 0.8395\n",
      "Epoch 38/150\n",
      "200000/200000 [==============================] - 34s 168us/step - loss: 0.2401 - acc: 0.9118 - auc: 0.8398\n",
      "Epoch 39/150\n",
      "200000/200000 [==============================] - 34s 168us/step - loss: 0.2399 - acc: 0.9117 - auc: 0.8399\n",
      "Epoch 40/150\n",
      "200000/200000 [==============================] - 34s 171us/step - loss: 0.2400 - acc: 0.9116 - auc: 0.8401\n",
      "Epoch 41/150\n",
      "200000/200000 [==============================] - 35s 176us/step - loss: 0.2398 - acc: 0.9117 - auc: 0.8403\n",
      "Epoch 42/150\n",
      "200000/200000 [==============================] - 35s 177us/step - loss: 0.2397 - acc: 0.9120 - auc: 0.8404\n",
      "Epoch 43/150\n",
      "200000/200000 [==============================] - 37s 183us/step - loss: 0.2395 - acc: 0.9118 - auc: 0.8406\n",
      "Epoch 44/150\n",
      "200000/200000 [==============================] - 36s 181us/step - loss: 0.2394 - acc: 0.9117 - auc: 0.8408\n",
      "Epoch 45/150\n",
      "200000/200000 [==============================] - 37s 186us/step - loss: 0.2394 - acc: 0.9120 - auc: 0.8409\n",
      "Epoch 46/150\n",
      "200000/200000 [==============================] - 36s 181us/step - loss: 0.2392 - acc: 0.9116 - auc: 0.8410\n",
      "Epoch 47/150\n",
      "200000/200000 [==============================] - 39s 193us/step - loss: 0.2390 - acc: 0.9120 - auc: 0.8412\n",
      "Epoch 48/150\n",
      "200000/200000 [==============================] - 36s 179us/step - loss: 0.2389 - acc: 0.9118 - auc: 0.8413\n",
      "Epoch 49/150\n",
      "200000/200000 [==============================] - 36s 178us/step - loss: 0.2390 - acc: 0.9120 - auc: 0.8415\n",
      "Epoch 50/150\n",
      "200000/200000 [==============================] - 36s 180us/step - loss: 0.2387 - acc: 0.9126 - auc: 0.8416\n",
      "Epoch 51/150\n",
      "200000/200000 [==============================] - 38s 188us/step - loss: 0.2387 - acc: 0.9122 - auc: 0.8418\n",
      "Epoch 52/150\n",
      "200000/200000 [==============================] - 38s 189us/step - loss: 0.2387 - acc: 0.9121 - auc: 0.8419\n",
      "Epoch 53/150\n",
      "200000/200000 [==============================] - 34s 169us/step - loss: 0.2386 - acc: 0.9122 - auc: 0.8420\n",
      "Epoch 54/150\n",
      "200000/200000 [==============================] - 35s 177us/step - loss: 0.2384 - acc: 0.9119 - auc: 0.8422\n",
      "Epoch 55/150\n",
      "200000/200000 [==============================] - 35s 177us/step - loss: 0.2384 - acc: 0.9120 - auc: 0.8423\n",
      "Epoch 56/150\n",
      "200000/200000 [==============================] - 35s 173us/step - loss: 0.2383 - acc: 0.9124 - auc: 0.8424\n",
      "Epoch 57/150\n",
      "200000/200000 [==============================] - 36s 181us/step - loss: 0.2381 - acc: 0.9125 - auc: 0.8425\n",
      "Epoch 58/150\n",
      "200000/200000 [==============================] - 35s 177us/step - loss: 0.2380 - acc: 0.9124 - auc: 0.8426\n",
      "Epoch 59/150\n",
      "200000/200000 [==============================] - 35s 175us/step - loss: 0.2380 - acc: 0.9125 - auc: 0.8428\n",
      "Epoch 60/150\n",
      "200000/200000 [==============================] - 34s 168us/step - loss: 0.2379 - acc: 0.9127 - auc: 0.8429\n",
      "Epoch 61/150\n",
      "200000/200000 [==============================] - 36s 179us/step - loss: 0.2379 - acc: 0.9123 - auc: 0.8430\n",
      "Epoch 62/150\n",
      "200000/200000 [==============================] - 41s 205us/step - loss: 0.2377 - acc: 0.9123 - auc: 0.8431\n",
      "Epoch 63/150\n",
      "200000/200000 [==============================] - 39s 195us/step - loss: 0.2379 - acc: 0.9125 - auc: 0.84321s - loss: 0.2379 - acc: 0.912\n",
      "Epoch 64/150\n",
      "200000/200000 [==============================] - 33s 167us/step - loss: 0.2377 - acc: 0.9121 - auc: 0.8433\n",
      "Epoch 65/150\n",
      "200000/200000 [==============================] - 37s 184us/step - loss: 0.2375 - acc: 0.9124 - auc: 0.8434\n",
      "Epoch 66/150\n",
      "200000/200000 [==============================] - 33s 163us/step - loss: 0.2376 - acc: 0.9128 - auc: 0.84352s - \n",
      "Epoch 67/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 35s 177us/step - loss: 0.2374 - acc: 0.9127 - auc: 0.84362s - loss: 0.2371 - acc: 0.9128 - auc: - ETA: 2s - lo\n",
      "Epoch 68/150\n",
      "200000/200000 [==============================] - 33s 164us/step - loss: 0.2374 - acc: 0.9125 - auc: 0.8437\n",
      "Epoch 69/150\n",
      "200000/200000 [==============================] - 34s 171us/step - loss: 0.2374 - acc: 0.9125 - auc: 0.8438\n",
      "Epoch 70/150\n",
      "200000/200000 [==============================] - 33s 165us/step - loss: 0.2374 - acc: 0.9127 - auc: 0.8439\n",
      "Epoch 71/150\n",
      "200000/200000 [==============================] - 34s 169us/step - loss: 0.2373 - acc: 0.9126 - auc: 0.8440\n",
      "Epoch 72/150\n",
      "200000/200000 [==============================] - 34s 172us/step - loss: 0.2371 - acc: 0.9126 - auc: 0.8441\n",
      "Epoch 73/150\n",
      "200000/200000 [==============================] - 33s 167us/step - loss: 0.2370 - acc: 0.9129 - auc: 0.8442\n",
      "Epoch 74/150\n",
      "200000/200000 [==============================] - 30s 150us/step - loss: 0.2371 - acc: 0.9127 - auc: 0.8443\n",
      "Epoch 75/150\n",
      "200000/200000 [==============================] - 33s 167us/step - loss: 0.2369 - acc: 0.9128 - auc: 0.8444\n",
      "Epoch 76/150\n",
      "200000/200000 [==============================] - 33s 167us/step - loss: 0.2367 - acc: 0.9128 - auc: 0.8445\n",
      "Epoch 77/150\n",
      "200000/200000 [==============================] - 34s 172us/step - loss: 0.2371 - acc: 0.9127 - auc: 0.8446\n",
      "Epoch 78/150\n",
      "200000/200000 [==============================] - 37s 186us/step - loss: 0.2368 - acc: 0.9128 - auc: 0.8447\n",
      "Epoch 79/150\n",
      "200000/200000 [==============================] - 31s 157us/step - loss: 0.2369 - acc: 0.9124 - auc: 0.8448\n",
      "Epoch 80/150\n",
      "200000/200000 [==============================] - 34s 171us/step - loss: 0.2368 - acc: 0.9128 - auc: 0.8449\n",
      "Epoch 81/150\n",
      "200000/200000 [==============================] - 32s 162us/step - loss: 0.2366 - acc: 0.9130 - auc: 0.8449\n",
      "Epoch 82/150\n",
      "200000/200000 [==============================] - 36s 180us/step - loss: 0.2367 - acc: 0.9128 - auc: 0.8450\n",
      "Epoch 83/150\n",
      "200000/200000 [==============================] - 33s 164us/step - loss: 0.2365 - acc: 0.9128 - auc: 0.8451\n",
      "Epoch 84/150\n",
      "200000/200000 [==============================] - 37s 184us/step - loss: 0.2364 - acc: 0.9131 - auc: 0.8452\n",
      "Epoch 85/150\n",
      "200000/200000 [==============================] - 34s 171us/step - loss: 0.2365 - acc: 0.9126 - auc: 0.8453\n",
      "Epoch 86/150\n",
      "200000/200000 [==============================] - 34s 171us/step - loss: 0.2364 - acc: 0.9127 - auc: 0.8453\n",
      "Epoch 87/150\n",
      "200000/200000 [==============================] - 33s 164us/step - loss: 0.2363 - acc: 0.9128 - auc: 0.8454\n",
      "Epoch 88/150\n",
      "200000/200000 [==============================] - 35s 174us/step - loss: 0.2363 - acc: 0.9132 - auc: 0.8455\n",
      "Epoch 89/150\n",
      "200000/200000 [==============================] - 34s 168us/step - loss: 0.2362 - acc: 0.9130 - auc: 0.8456\n",
      "Epoch 90/150\n",
      "200000/200000 [==============================] - 33s 167us/step - loss: 0.2363 - acc: 0.9128 - auc: 0.8456\n",
      "Epoch 91/150\n",
      "200000/200000 [==============================] - 34s 168us/step - loss: 0.2360 - acc: 0.9127 - auc: 0.8457\n",
      "Epoch 92/150\n",
      "200000/200000 [==============================] - 33s 166us/step - loss: 0.2362 - acc: 0.9129 - auc: 0.8458\n",
      "Epoch 93/150\n",
      "200000/200000 [==============================] - 34s 170us/step - loss: 0.2360 - acc: 0.9131 - auc: 0.8459\n",
      "Epoch 94/150\n",
      "200000/200000 [==============================] - 33s 166us/step - loss: 0.2359 - acc: 0.9130 - auc: 0.8459\n",
      "Epoch 95/150\n",
      "200000/200000 [==============================] - 34s 171us/step - loss: 0.2362 - acc: 0.9131 - auc: 0.8460\n",
      "Epoch 96/150\n",
      "200000/200000 [==============================] - 34s 168us/step - loss: 0.2360 - acc: 0.9133 - auc: 0.8461\n",
      "Epoch 97/150\n",
      "200000/200000 [==============================] - 34s 168us/step - loss: 0.2358 - acc: 0.9135 - auc: 0.8461\n",
      "Epoch 98/150\n",
      "200000/200000 [==============================] - 34s 170us/step - loss: 0.2361 - acc: 0.9131 - auc: 0.8462\n",
      "Epoch 99/150\n",
      "200000/200000 [==============================] - 35s 173us/step - loss: 0.2358 - acc: 0.9131 - auc: 0.8463\n",
      "Epoch 100/150\n",
      "200000/200000 [==============================] - 34s 169us/step - loss: 0.2357 - acc: 0.9131 - auc: 0.8463\n",
      "Epoch 101/150\n",
      "200000/200000 [==============================] - 33s 167us/step - loss: 0.2359 - acc: 0.9131 - auc: 0.8464\n",
      "Epoch 102/150\n",
      "200000/200000 [==============================] - 35s 176us/step - loss: 0.2360 - acc: 0.9131 - auc: 0.8465\n",
      "Epoch 103/150\n",
      "200000/200000 [==============================] - 35s 176us/step - loss: 0.2357 - acc: 0.9132 - auc: 0.8465\n",
      "Epoch 104/150\n",
      "200000/200000 [==============================] - 38s 190us/step - loss: 0.2356 - acc: 0.9133 - auc: 0.8466\n",
      "Epoch 105/150\n",
      "200000/200000 [==============================] - 34s 171us/step - loss: 0.2355 - acc: 0.9130 - auc: 0.8467\n",
      "Epoch 106/150\n",
      "200000/200000 [==============================] - 34s 170us/step - loss: 0.2355 - acc: 0.9134 - auc: 0.8467\n",
      "Epoch 107/150\n",
      "200000/200000 [==============================] - 33s 167us/step - loss: 0.2356 - acc: 0.9134 - auc: 0.8468\n",
      "Epoch 108/150\n",
      "200000/200000 [==============================] - 34s 172us/step - loss: 0.2355 - acc: 0.9132 - auc: 0.8468\n",
      "Epoch 109/150\n",
      "200000/200000 [==============================] - 34s 168us/step - loss: 0.2356 - acc: 0.9132 - auc: 0.8469\n",
      "Epoch 110/150\n",
      "200000/200000 [==============================] - 34s 170us/step - loss: 0.2362 - acc: 0.9130 - auc: 0.8469\n",
      "Epoch 111/150\n",
      "200000/200000 [==============================] - 36s 180us/step - loss: 0.2361 - acc: 0.9132 - auc: 0.8470\n",
      "Epoch 112/150\n",
      "200000/200000 [==============================] - 34s 168us/step - loss: 0.2363 - acc: 0.9127 - auc: 0.8470\n",
      "Epoch 113/150\n",
      "200000/200000 [==============================] - 34s 169us/step - loss: 0.2360 - acc: 0.9134 - auc: 0.8471\n",
      "Epoch 114/150\n",
      "200000/200000 [==============================] - 34s 169us/step - loss: 0.2359 - acc: 0.9131 - auc: 0.8471\n",
      "Epoch 115/150\n",
      "200000/200000 [==============================] - 34s 172us/step - loss: 0.2359 - acc: 0.9133 - auc: 0.8472\n",
      "Epoch 116/150\n",
      "200000/200000 [==============================] - 34s 170us/step - loss: 0.2359 - acc: 0.9130 - auc: 0.8472\n",
      "Epoch 117/150\n",
      "200000/200000 [==============================] - 34s 172us/step - loss: 0.2357 - acc: 0.9131 - auc: 0.8473\n",
      "Epoch 118/150\n",
      "200000/200000 [==============================] - 34s 169us/step - loss: 0.2358 - acc: 0.9133 - auc: 0.8473\n",
      "Epoch 119/150\n",
      "200000/200000 [==============================] - 34s 170us/step - loss: 0.2359 - acc: 0.9130 - auc: 0.84741s - loss: 0.2360 - a\n",
      "Epoch 120/150\n",
      "200000/200000 [==============================] - 36s 180us/step - loss: 0.2358 - acc: 0.9130 - auc: 0.8474\n",
      "Epoch 121/150\n",
      "200000/200000 [==============================] - 35s 175us/step - loss: 0.2357 - acc: 0.9133 - auc: 0.8475\n",
      "Epoch 122/150\n",
      "200000/200000 [==============================] - 35s 176us/step - loss: 0.2357 - acc: 0.9134 - auc: 0.8475\n",
      "Epoch 123/150\n",
      "200000/200000 [==============================] - 34s 171us/step - loss: 0.2357 - acc: 0.9132 - auc: 0.8475\n",
      "Epoch 124/150\n",
      "200000/200000 [==============================] - 35s 176us/step - loss: 0.2359 - acc: 0.9136 - auc: 0.8476\n",
      "Epoch 125/150\n",
      "200000/200000 [==============================] - 34s 169us/step - loss: 0.2356 - acc: 0.9134 - auc: 0.8476\n",
      "Epoch 126/150\n",
      "200000/200000 [==============================] - 35s 176us/step - loss: 0.2357 - acc: 0.9132 - auc: 0.8477\n",
      "Epoch 127/150\n",
      "200000/200000 [==============================] - 34s 168us/step - loss: 0.2356 - acc: 0.9134 - auc: 0.8477\n",
      "Epoch 128/150\n",
      "200000/200000 [==============================] - 35s 173us/step - loss: 0.2354 - acc: 0.9129 - auc: 0.8478\n",
      "Epoch 129/150\n",
      "200000/200000 [==============================] - 34s 169us/step - loss: 0.2355 - acc: 0.9135 - auc: 0.8478\n",
      "Epoch 130/150\n",
      "200000/200000 [==============================] - 35s 173us/step - loss: 0.2355 - acc: 0.9136 - auc: 0.8478\n",
      "Epoch 131/150\n",
      "200000/200000 [==============================] - 35s 176us/step - loss: 0.2354 - acc: 0.9132 - auc: 0.8479\n",
      "Epoch 132/150\n",
      "200000/200000 [==============================] - 34s 169us/step - loss: 0.2353 - acc: 0.9129 - auc: 0.8479\n",
      "Epoch 133/150\n",
      "200000/200000 [==============================] - 35s 174us/step - loss: 0.2355 - acc: 0.9132 - auc: 0.8480\n",
      "Epoch 134/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 32s 158us/step - loss: 0.2355 - acc: 0.9134 - auc: 0.8480\n",
      "Epoch 135/150\n",
      "200000/200000 [==============================] - 32s 158us/step - loss: 0.2352 - acc: 0.9137 - auc: 0.8480\n",
      "Epoch 136/150\n",
      "200000/200000 [==============================] - 33s 167us/step - loss: 0.2350 - acc: 0.9135 - auc: 0.8481\n",
      "Epoch 137/150\n",
      "200000/200000 [==============================] - 34s 171us/step - loss: 0.2352 - acc: 0.9131 - auc: 0.8481\n",
      "Epoch 138/150\n",
      "200000/200000 [==============================] - 33s 163us/step - loss: 0.2352 - acc: 0.9133 - auc: 0.8482\n",
      "Epoch 139/150\n",
      "200000/200000 [==============================] - 33s 164us/step - loss: 0.2350 - acc: 0.9133 - auc: 0.8482\n",
      "Epoch 140/150\n",
      "200000/200000 [==============================] - 31s 154us/step - loss: 0.2352 - acc: 0.9136 - auc: 0.8482\n",
      "Epoch 141/150\n",
      "200000/200000 [==============================] - 34s 169us/step - loss: 0.2350 - acc: 0.9133 - auc: 0.8483\n",
      "Epoch 142/150\n",
      "200000/200000 [==============================] - 34s 168us/step - loss: 0.2349 - acc: 0.9137 - auc: 0.8483\n",
      "Epoch 143/150\n",
      "200000/200000 [==============================] - 34s 170us/step - loss: 0.2349 - acc: 0.9133 - auc: 0.8484\n",
      "Epoch 144/150\n",
      "200000/200000 [==============================] - 33s 167us/step - loss: 0.2348 - acc: 0.9134 - auc: 0.8484\n",
      "Epoch 145/150\n",
      "200000/200000 [==============================] - 35s 173us/step - loss: 0.2350 - acc: 0.9134 - auc: 0.8485\n",
      "Epoch 146/150\n",
      "200000/200000 [==============================] - 34s 171us/step - loss: 0.2349 - acc: 0.9134 - auc: 0.8485\n",
      "Epoch 147/150\n",
      "200000/200000 [==============================] - 33s 166us/step - loss: 0.2350 - acc: 0.9135 - auc: 0.8485\n",
      "Epoch 148/150\n",
      "200000/200000 [==============================] - 34s 168us/step - loss: 0.2349 - acc: 0.9138 - auc: 0.84860s - loss: 0.2349 - acc: 0.9138 - auc: 0.8\n",
      "Epoch 149/150\n",
      "200000/200000 [==============================] - 33s 167us/step - loss: 0.2348 - acc: 0.9134 - auc: 0.8486\n",
      "Epoch 150/150\n",
      "200000/200000 [==============================] - 34s 172us/step - loss: 0.2348 - acc: 0.9134 - auc: 0.8486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x287fb9d2da0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(features,target, batch_size = 10, epochs = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=classifier.predict(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (predictions > 0.45)\n",
    "pred=pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"ID_code\": test.ID_code.values})\n",
    "submission[\"target\"] = pred\n",
    "submission.to_csv(\"submission_nn4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code  target\n",
       "0  test_0       0\n",
       "1  test_1       0\n",
       "2  test_2       0\n",
       "3  test_3       0\n",
       "4  test_4       0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 100000\n",
    "\n",
    "folds = StratifiedKFold(n_splits=12, shuffle=False, random_state=100)\n",
    "oof = np.zeros(len(features))\n",
    "predictions = np.zeros(len(test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.882322\tvalid_1's auc: 0.862248\n"
     ]
    }
   ],
   "source": [
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(features.values, target.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(features.iloc[trn_idx], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(features.iloc[val_idx], label=target.iloc[val_idx])\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 2500)\n",
    "    oof[val_idx] = clf.predict(features.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "    predictions += clf.predict(test2, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
