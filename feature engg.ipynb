{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "940d17583b43f57135c935b86d217f2b52c2c35e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7   ...     var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266   ...      4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338   ...      7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155   ...      2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250   ...      4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "f3cbf989cc0edc36f296504167e7dd18c6dc0459"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 202)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "369f77a48aae93d07691cc973136ccd127f180fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1de3e0fc4e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.var_126.plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "e0157f348b2395b3b63b9277fdbc9199a069f97c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sreekar chidurala\\Anaconda3\\envs\\sreekar\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400000, 202)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge test and train\n",
    "merged = pd.concat([train, test])\n",
    "#Saving the list of original features in a new list `original_features`.\n",
    "original_features = merged.columns\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "7a7035772c236994b17d875e6aa1a7d1895c3503"
   },
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "_uuid": "c13a6ef6c37036de474f5f5aa21ee8d45239693f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27317d66748>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.target.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "_uuid": "4f76189fb3b53e38e16d3a97dcefb216329f230a"
   },
   "outputs": [],
   "source": [
    "#well ,we'll go with smote if we get less accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_uuid": "bed21550eab46493390cf59327c5142272f26bea"
   },
   "outputs": [],
   "source": [
    "idx = features = merged.columns.values[0:200]\n",
    "for df in [merged]:\n",
    "    df['sum'] = df[idx].sum(axis=1)  \n",
    "    df['max'] = df[idx].max(axis=1)\n",
    "    df['mean'] = df[idx].mean(axis=1)\n",
    "    df['std'] = df[idx].std(axis=1)\n",
    "    df['skew'] = df[idx].skew(axis=1)\n",
    "    df['kurt'] = df[idx].kurtosis(axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "b9d584161a4d023c87247ae043f0e3640049dc49"
   },
   "outputs": [],
   "source": [
    "merged[\"new\"]=merged[\"var_108\"]*merged[\"var_63\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "0094313ec5eade26334b57e72fcb852f3bce31ea"
   },
   "outputs": [],
   "source": [
    "\n",
    "merged[\"log_73\"]=np.log(merged[\"var_73\"]+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "f356052ef1e65ab8bf76eb0ff7750b76aebecee7"
   },
   "outputs": [],
   "source": [
    "merged[\"log_1\"]=np.log(merged[\"var_1\"]+17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "de5b3227903201a86fc25eaddb9367129f63c1db"
   },
   "outputs": [],
   "source": [
    "merged[\"log_1*73\"]=merged[\"log_73\"]*merged[\"log_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "42690204479d1f8fe3a688870ddbece0c5e471f7"
   },
   "outputs": [],
   "source": [
    "merged[\"var_2_sq\"]=merged[\"var_2\"]*merged[\"var_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"var_10_100_101\"]=merged[\"var_10\"]-merged[\"var_100\"]-merged[\"var_101\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 81 , 139 , 12, 110 , 26 , 53 , 146 , 6 ,22 , 166 , 80 , 174 , 109 , 76 , 21 , 13 , 99 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"log_81\"]=np.log(merged[\"var_81\"]+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"log_1*81\"]=merged[\"log_81\"]*merged[\"log_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"var_12_110_101\"]=merged[\"var_12\"]-merged[\"var_110\"]-merged[\"var_101\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"var_166_80_174\"]=merged[\"var_166\"]-merged[\"var_80\"]-merged[\"var_174\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"new1\"]=merged[\"var_146\"]*merged[\"var_6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"new2\"]=merged[\"var_146\"]*merged[\"var_80\"]*merged[\"var_21\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"var_10_100_21\"]=merged[\"var_10\"]-merged[\"var_100\"]-merged[\"var_21\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"log_13\"]=np.log(merged[\"var_13\"]+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"var_10_100_21_13\"]=merged[\"var_10\"]-merged[\"var_100\"]-merged[\"var_21\"]+merged[\"log_13\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"var_6_cube\"]=merged[\"var_6\"]*merged[\"var_6\"]*merged[\"var_80\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"var_10_109_21\"]=merged[\"var_16\"]-merged[\"var_156\"]-merged[\"var_98\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"var_134_100_101\"]=merged[\"var_17\"]+merged[\"var_166\"]-merged[\"var_8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"log_17\"]=np.log(merged[\"var_17\"]+40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"var_134_100_101_log17\"]=merged[\"var_17\"]+merged[\"var_166\"]-merged[\"var_8\"] * merged[\"log_17\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"new5\"]=merged[\"var_145\"]*merged[\"var_88\"]-merged[\"var_20\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"var_10_100_201_13\"]=merged[\"var_101\"]*merged[\"var_109\"]-merged[\"var_89\"]+merged[\"var_23\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"new9\"]=merged[\"var_146\"]*merged[\"var_6\"]-merged[\"var_10_100_201_13\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"var_10_100_2455\"]=merged[\"var_105\"]+merged[\"var_187\"]*merged[\"var_25\"]-merged[\"new9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "f52c0db11a395951fba975cd483c990bae826803"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_10</th>\n",
       "      <th>var_100</th>\n",
       "      <th>var_101</th>\n",
       "      <th>var_102</th>\n",
       "      <th>var_103</th>\n",
       "      <th>var_104</th>\n",
       "      <th>...</th>\n",
       "      <th>var_10_100_21_13</th>\n",
       "      <th>var_6_cube</th>\n",
       "      <th>var_10_109_21</th>\n",
       "      <th>var_134_100_101</th>\n",
       "      <th>log_17</th>\n",
       "      <th>var_134_100_101_log17</th>\n",
       "      <th>new5</th>\n",
       "      <th>var_10_100_201_13</th>\n",
       "      <th>new9</th>\n",
       "      <th>var_10_100_2455</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>2.9252</td>\n",
       "      <td>9.4763</td>\n",
       "      <td>13.3102</td>\n",
       "      <td>26.5376</td>\n",
       "      <td>1.4403</td>\n",
       "      <td>14.7100</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.411755</td>\n",
       "      <td>357.561031</td>\n",
       "      <td>-8.6005</td>\n",
       "      <td>0.3811</td>\n",
       "      <td>3.489230</td>\n",
       "      <td>12.628110</td>\n",
       "      <td>56.406809</td>\n",
       "      <td>328.450910</td>\n",
       "      <td>-269.248537</td>\n",
       "      <td>10.460110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>-0.4032</td>\n",
       "      <td>-13.6950</td>\n",
       "      <td>8.4068</td>\n",
       "      <td>35.4734</td>\n",
       "      <td>1.7093</td>\n",
       "      <td>15.1866</td>\n",
       "      <td>...</td>\n",
       "      <td>13.464184</td>\n",
       "      <td>80.443096</td>\n",
       "      <td>-0.3088</td>\n",
       "      <td>-15.5314</td>\n",
       "      <td>3.195202</td>\n",
       "      <td>-22.439261</td>\n",
       "      <td>84.078682</td>\n",
       "      <td>101.151203</td>\n",
       "      <td>-50.996243</td>\n",
       "      <td>-167.691080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>-0.3249</td>\n",
       "      <td>-0.3939</td>\n",
       "      <td>12.6317</td>\n",
       "      <td>14.8863</td>\n",
       "      <td>1.3854</td>\n",
       "      <td>15.0284</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.217277</td>\n",
       "      <td>360.201875</td>\n",
       "      <td>-8.5561</td>\n",
       "      <td>6.4588</td>\n",
       "      <td>3.644418</td>\n",
       "      <td>19.467486</td>\n",
       "      <td>34.209107</td>\n",
       "      <td>258.906626</td>\n",
       "      <td>-179.111398</td>\n",
       "      <td>100.288790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>2.3061</td>\n",
       "      <td>-19.8592</td>\n",
       "      <td>22.5316</td>\n",
       "      <td>18.6129</td>\n",
       "      <td>1.3512</td>\n",
       "      <td>9.3291</td>\n",
       "      <td>...</td>\n",
       "      <td>12.697096</td>\n",
       "      <td>26.761023</td>\n",
       "      <td>-4.1414</td>\n",
       "      <td>8.0191</td>\n",
       "      <td>3.678074</td>\n",
       "      <td>23.715023</td>\n",
       "      <td>-6.998491</td>\n",
       "      <td>319.931217</td>\n",
       "      <td>-258.585322</td>\n",
       "      <td>86.655808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>-9.4458</td>\n",
       "      <td>-22.9264</td>\n",
       "      <td>12.3562</td>\n",
       "      <td>17.3410</td>\n",
       "      <td>1.6940</td>\n",
       "      <td>7.1179</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.595986</td>\n",
       "      <td>104.449981</td>\n",
       "      <td>-6.1994</td>\n",
       "      <td>-6.1030</td>\n",
       "      <td>3.609078</td>\n",
       "      <td>-22.449920</td>\n",
       "      <td>51.879932</td>\n",
       "      <td>348.289119</td>\n",
       "      <td>-279.575356</td>\n",
       "      <td>365.039895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1  var_10  var_100  var_101  var_102  \\\n",
       "0  train_0     0.0   8.9255 -6.7863  2.9252   9.4763  13.3102  26.5376   \n",
       "1  train_1     0.0  11.5006 -4.1473 -0.4032 -13.6950   8.4068  35.4734   \n",
       "2  train_2     0.0   8.6093 -2.7457 -0.3249  -0.3939  12.6317  14.8863   \n",
       "3  train_3     0.0  11.0604 -2.1518  2.3061 -19.8592  22.5316  18.6129   \n",
       "4  train_4     0.0   9.8369 -1.4834 -9.4458 -22.9264  12.3562  17.3410   \n",
       "\n",
       "   var_103  var_104       ...         var_10_100_21_13  var_6_cube  \\\n",
       "0   1.4403  14.7100       ...               -20.411755  357.561031   \n",
       "1   1.7093  15.1866       ...                13.464184   80.443096   \n",
       "2   1.3854  15.0284       ...               -15.217277  360.201875   \n",
       "3   1.3512   9.3291       ...                12.697096   26.761023   \n",
       "4   1.6940   7.1179       ...                -2.595986  104.449981   \n",
       "\n",
       "   var_10_109_21  var_134_100_101    log_17  var_134_100_101_log17       new5  \\\n",
       "0        -8.6005           0.3811  3.489230              12.628110  56.406809   \n",
       "1        -0.3088         -15.5314  3.195202             -22.439261  84.078682   \n",
       "2        -8.5561           6.4588  3.644418              19.467486  34.209107   \n",
       "3        -4.1414           8.0191  3.678074              23.715023  -6.998491   \n",
       "4        -6.1994          -6.1030  3.609078             -22.449920  51.879932   \n",
       "\n",
       "   var_10_100_201_13        new9  var_10_100_2455  \n",
       "0         328.450910 -269.248537        10.460110  \n",
       "1         101.151203  -50.996243      -167.691080  \n",
       "2         258.906626 -179.111398       100.288790  \n",
       "3         319.931217 -258.585322        86.655808  \n",
       "4         348.289119 -279.575356       365.039895  \n",
       "\n",
       "[5 rows x 226 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = merged.iloc[:len(train)]\n",
    "X = train\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "bb97d0b8f8b80676156f204e46ec592f225b724d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_10</th>\n",
       "      <th>var_100</th>\n",
       "      <th>var_101</th>\n",
       "      <th>var_102</th>\n",
       "      <th>var_103</th>\n",
       "      <th>var_104</th>\n",
       "      <th>...</th>\n",
       "      <th>var_10_100_21_13</th>\n",
       "      <th>var_6_cube</th>\n",
       "      <th>var_10_109_21</th>\n",
       "      <th>var_134_100_101</th>\n",
       "      <th>log_17</th>\n",
       "      <th>var_134_100_101_log17</th>\n",
       "      <th>new5</th>\n",
       "      <th>var_10_100_201_13</th>\n",
       "      <th>new9</th>\n",
       "      <th>var_10_100_2455</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>-2.0248</td>\n",
       "      <td>-9.2198</td>\n",
       "      <td>17.3089</td>\n",
       "      <td>30.9548</td>\n",
       "      <td>1.4918</td>\n",
       "      <td>12.8721</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.274819</td>\n",
       "      <td>324.635642</td>\n",
       "      <td>-6.3348</td>\n",
       "      <td>-18.6725</td>\n",
       "      <td>3.040137</td>\n",
       "      <td>-23.025540</td>\n",
       "      <td>36.061478</td>\n",
       "      <td>256.088869</td>\n",
       "      <td>-187.773140</td>\n",
       "      <td>-141.533264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>-1.3809</td>\n",
       "      <td>-1.7257</td>\n",
       "      <td>15.4712</td>\n",
       "      <td>35.6020</td>\n",
       "      <td>1.6570</td>\n",
       "      <td>13.0783</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263050</td>\n",
       "      <td>71.644997</td>\n",
       "      <td>-9.8481</td>\n",
       "      <td>12.2880</td>\n",
       "      <td>3.798998</td>\n",
       "      <td>24.640256</td>\n",
       "      <td>-53.542356</td>\n",
       "      <td>274.060938</td>\n",
       "      <td>-221.302756</td>\n",
       "      <td>106.456720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>-4.7057</td>\n",
       "      <td>-3.5065</td>\n",
       "      <td>14.1663</td>\n",
       "      <td>28.0256</td>\n",
       "      <td>1.3935</td>\n",
       "      <td>10.8257</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.942806</td>\n",
       "      <td>387.428209</td>\n",
       "      <td>-4.1631</td>\n",
       "      <td>4.2551</td>\n",
       "      <td>3.753123</td>\n",
       "      <td>0.061267</td>\n",
       "      <td>-13.281539</td>\n",
       "      <td>283.619765</td>\n",
       "      <td>-226.471129</td>\n",
       "      <td>202.655705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>1.7021</td>\n",
       "      <td>2.5363</td>\n",
       "      <td>3.8763</td>\n",
       "      <td>1.5173</td>\n",
       "      <td>13.4083</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.088257</td>\n",
       "      <td>429.307231</td>\n",
       "      <td>-4.9757</td>\n",
       "      <td>-16.0848</td>\n",
       "      <td>3.204744</td>\n",
       "      <td>-23.526915</td>\n",
       "      <td>4.995591</td>\n",
       "      <td>62.342436</td>\n",
       "      <td>-19.385323</td>\n",
       "      <td>-257.450069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>5.1025</td>\n",
       "      <td>-14.3858</td>\n",
       "      <td>17.8630</td>\n",
       "      <td>23.2274</td>\n",
       "      <td>1.4375</td>\n",
       "      <td>14.4838</td>\n",
       "      <td>...</td>\n",
       "      <td>6.125111</td>\n",
       "      <td>555.848136</td>\n",
       "      <td>-2.8154</td>\n",
       "      <td>3.3938</td>\n",
       "      <td>3.764636</td>\n",
       "      <td>-4.869697</td>\n",
       "      <td>-7.403807</td>\n",
       "      <td>289.122359</td>\n",
       "      <td>-200.410504</td>\n",
       "      <td>-139.802826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code  target    var_0    var_1  var_10  var_100  var_101  var_102  \\\n",
       "0  test_0     NaN  11.0656   7.7798 -2.0248  -9.2198  17.3089  30.9548   \n",
       "1  test_1     NaN   8.5304   1.2543 -1.3809  -1.7257  15.4712  35.6020   \n",
       "2  test_2     NaN   5.4827 -10.3581 -4.7057  -3.5065  14.1663  28.0256   \n",
       "3  test_3     NaN   8.5374  -1.3222  0.0095   1.7021   2.5363   3.8763   \n",
       "4  test_4     NaN  11.7058  -0.1327  5.1025 -14.3858  17.8630  23.2274   \n",
       "\n",
       "   var_103  var_104       ...         var_10_100_21_13  var_6_cube  \\\n",
       "0   1.4918  12.8721       ...                -9.274819  324.635642   \n",
       "1   1.6570  13.0783       ...                -0.263050   71.644997   \n",
       "2   1.3935  10.8257       ...               -10.942806  387.428209   \n",
       "3   1.5173  13.4083       ...               -11.088257  429.307231   \n",
       "4   1.4375  14.4838       ...                 6.125111  555.848136   \n",
       "\n",
       "   var_10_109_21  var_134_100_101    log_17  var_134_100_101_log17       new5  \\\n",
       "0        -6.3348         -18.6725  3.040137             -23.025540  36.061478   \n",
       "1        -9.8481          12.2880  3.798998              24.640256 -53.542356   \n",
       "2        -4.1631           4.2551  3.753123               0.061267 -13.281539   \n",
       "3        -4.9757         -16.0848  3.204744             -23.526915   4.995591   \n",
       "4        -2.8154           3.3938  3.764636              -4.869697  -7.403807   \n",
       "\n",
       "   var_10_100_201_13        new9  var_10_100_2455  \n",
       "0         256.088869 -187.773140      -141.533264  \n",
       "1         274.060938 -221.302756       106.456720  \n",
       "2         283.619765 -226.471129       202.655705  \n",
       "3          62.342436  -19.385323      -257.450069  \n",
       "4         289.122359 -200.410504      -139.802826  \n",
       "\n",
       "[5 rows x 226 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = merged.iloc[len(train):]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "bc6dd39d84ffb94d0511f82f71e17524a893f9f0"
   },
   "outputs": [],
   "source": [
    "test2=test.drop([\"target\",\"ID_code\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "40f94f1b601c5eda3b86715b2badd293cd4f2bde"
   },
   "outputs": [],
   "source": [
    "features=train.drop([\"ID_code\",\"target\"],1)\n",
    "target=train[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_10</th>\n",
       "      <th>var_100</th>\n",
       "      <th>var_101</th>\n",
       "      <th>var_102</th>\n",
       "      <th>var_103</th>\n",
       "      <th>var_104</th>\n",
       "      <th>var_105</th>\n",
       "      <th>var_106</th>\n",
       "      <th>...</th>\n",
       "      <th>var_10_100_21_13</th>\n",
       "      <th>var_6_cube</th>\n",
       "      <th>var_10_109_21</th>\n",
       "      <th>var_134_100_101</th>\n",
       "      <th>log_17</th>\n",
       "      <th>var_134_100_101_log17</th>\n",
       "      <th>new5</th>\n",
       "      <th>var_10_100_201_13</th>\n",
       "      <th>new9</th>\n",
       "      <th>var_10_100_2455</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>2.9252</td>\n",
       "      <td>9.4763</td>\n",
       "      <td>13.3102</td>\n",
       "      <td>26.5376</td>\n",
       "      <td>1.4403</td>\n",
       "      <td>14.7100</td>\n",
       "      <td>6.0454</td>\n",
       "      <td>9.5426</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.411755</td>\n",
       "      <td>357.561031</td>\n",
       "      <td>-8.6005</td>\n",
       "      <td>0.3811</td>\n",
       "      <td>3.489230</td>\n",
       "      <td>12.628110</td>\n",
       "      <td>56.406809</td>\n",
       "      <td>328.450910</td>\n",
       "      <td>-269.248537</td>\n",
       "      <td>10.460110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>-0.4032</td>\n",
       "      <td>-13.6950</td>\n",
       "      <td>8.4068</td>\n",
       "      <td>35.4734</td>\n",
       "      <td>1.7093</td>\n",
       "      <td>15.1866</td>\n",
       "      <td>2.6227</td>\n",
       "      <td>7.3412</td>\n",
       "      <td>...</td>\n",
       "      <td>13.464184</td>\n",
       "      <td>80.443096</td>\n",
       "      <td>-0.3088</td>\n",
       "      <td>-15.5314</td>\n",
       "      <td>3.195202</td>\n",
       "      <td>-22.439261</td>\n",
       "      <td>84.078682</td>\n",
       "      <td>101.151203</td>\n",
       "      <td>-50.996243</td>\n",
       "      <td>-167.691080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>-0.3249</td>\n",
       "      <td>-0.3939</td>\n",
       "      <td>12.6317</td>\n",
       "      <td>14.8863</td>\n",
       "      <td>1.3854</td>\n",
       "      <td>15.0284</td>\n",
       "      <td>3.9995</td>\n",
       "      <td>5.3683</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.217277</td>\n",
       "      <td>360.201875</td>\n",
       "      <td>-8.5561</td>\n",
       "      <td>6.4588</td>\n",
       "      <td>3.644418</td>\n",
       "      <td>19.467486</td>\n",
       "      <td>34.209107</td>\n",
       "      <td>258.906626</td>\n",
       "      <td>-179.111398</td>\n",
       "      <td>100.288790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>2.3061</td>\n",
       "      <td>-19.8592</td>\n",
       "      <td>22.5316</td>\n",
       "      <td>18.6129</td>\n",
       "      <td>1.3512</td>\n",
       "      <td>9.3291</td>\n",
       "      <td>4.2835</td>\n",
       "      <td>10.3907</td>\n",
       "      <td>...</td>\n",
       "      <td>12.697096</td>\n",
       "      <td>26.761023</td>\n",
       "      <td>-4.1414</td>\n",
       "      <td>8.0191</td>\n",
       "      <td>3.678074</td>\n",
       "      <td>23.715023</td>\n",
       "      <td>-6.998491</td>\n",
       "      <td>319.931217</td>\n",
       "      <td>-258.585322</td>\n",
       "      <td>86.655808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>-9.4458</td>\n",
       "      <td>-22.9264</td>\n",
       "      <td>12.3562</td>\n",
       "      <td>17.3410</td>\n",
       "      <td>1.6940</td>\n",
       "      <td>7.1179</td>\n",
       "      <td>5.1934</td>\n",
       "      <td>8.8230</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.595986</td>\n",
       "      <td>104.449981</td>\n",
       "      <td>-6.1994</td>\n",
       "      <td>-6.1030</td>\n",
       "      <td>3.609078</td>\n",
       "      <td>-22.449920</td>\n",
       "      <td>51.879932</td>\n",
       "      <td>348.289119</td>\n",
       "      <td>-279.575356</td>\n",
       "      <td>365.039895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 224 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0   var_1  var_10  var_100  var_101  var_102  var_103  var_104  \\\n",
       "0   8.9255 -6.7863  2.9252   9.4763  13.3102  26.5376   1.4403  14.7100   \n",
       "1  11.5006 -4.1473 -0.4032 -13.6950   8.4068  35.4734   1.7093  15.1866   \n",
       "2   8.6093 -2.7457 -0.3249  -0.3939  12.6317  14.8863   1.3854  15.0284   \n",
       "3  11.0604 -2.1518  2.3061 -19.8592  22.5316  18.6129   1.3512   9.3291   \n",
       "4   9.8369 -1.4834 -9.4458 -22.9264  12.3562  17.3410   1.6940   7.1179   \n",
       "\n",
       "   var_105  var_106       ...         var_10_100_21_13  var_6_cube  \\\n",
       "0   6.0454   9.5426       ...               -20.411755  357.561031   \n",
       "1   2.6227   7.3412       ...                13.464184   80.443096   \n",
       "2   3.9995   5.3683       ...               -15.217277  360.201875   \n",
       "3   4.2835  10.3907       ...                12.697096   26.761023   \n",
       "4   5.1934   8.8230       ...                -2.595986  104.449981   \n",
       "\n",
       "   var_10_109_21  var_134_100_101    log_17  var_134_100_101_log17       new5  \\\n",
       "0        -8.6005           0.3811  3.489230              12.628110  56.406809   \n",
       "1        -0.3088         -15.5314  3.195202             -22.439261  84.078682   \n",
       "2        -8.5561           6.4588  3.644418              19.467486  34.209107   \n",
       "3        -4.1414           8.0191  3.678074              23.715023  -6.998491   \n",
       "4        -6.1994          -6.1030  3.609078             -22.449920  51.879932   \n",
       "\n",
       "   var_10_100_201_13        new9  var_10_100_2455  \n",
       "0         328.450910 -269.248537        10.460110  \n",
       "1         101.151203  -50.996243      -167.691080  \n",
       "2         258.906626 -179.111398       100.288790  \n",
       "3         319.931217 -258.585322        86.655808  \n",
       "4         348.289119 -279.575356       365.039895  \n",
       "\n",
       "[5 rows x 224 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(features)\n",
    "features = scaler.transform(features)\n",
    "test2 = scaler.transform(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=pd.DataFrame(features)\n",
    "test2=pd.DataFrame(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5. 10.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.linspace(start = 5, stop = 10, num = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [10, 15], 'max_features': ['auto', 'log2'], 'max_depth': [5, 10, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10 , stop = 15, num = 2)]   # returns evenly spaced 10 numbers\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 10, num = 2)]  # returns evenly spaced numbers can be changed to any\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  3.7min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state = 100)\n",
    "# Use the random grid to search for best hyperparameters\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n",
    "                              n_iter = 5,  \n",
    "                              cv = 3, verbose=2, random_state=42, n_jobs=-1,\n",
    "                              return_train_score=True)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(features,target);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "best_random= best_random.fit(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=best_random.predict(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"ID_code\": test.ID_code.values})\n",
    "submission[\"target\"] = predictions\n",
    "submission.to_csv(\"submission_rf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "_uuid": "a38cc1db174f3c4a0adda68a7c091af04558e174"
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.33,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.05,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1,\n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 80,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,\n",
    "    'num_threads': 12,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary',\n",
    "    'verbosity': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "_uuid": "ecafc0f0e4bed10abbb93e8556bbfe14e39497ff"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "_uuid": "5ba5d7ead2ccbf5ca15f81c65bd52a67f875e611"
   },
   "outputs": [],
   "source": [
    "num_round = 100000\n",
    "folds = StratifiedKFold(n_splits=15, shuffle=False, random_state=100)\n",
    "oof = np.zeros(len(features))\n",
    "predictions = np.zeros(len(test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "_uuid": "d8837fb844e778450a0a6b6e8b2fdba43a65030a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.893128\tvalid_1's auc: 0.876049\n",
      "[2000]\ttraining's auc: 0.908288\tvalid_1's auc: 0.888695\n",
      "[3000]\ttraining's auc: 0.917065\tvalid_1's auc: 0.893849\n",
      "[4000]\ttraining's auc: 0.923434\tvalid_1's auc: 0.897181\n",
      "[5000]\ttraining's auc: 0.928538\tvalid_1's auc: 0.899024\n",
      "[6000]\ttraining's auc: 0.93291\tvalid_1's auc: 0.900195\n",
      "[7000]\ttraining's auc: 0.936899\tvalid_1's auc: 0.901042\n",
      "[8000]\ttraining's auc: 0.940627\tvalid_1's auc: 0.901122\n",
      "[9000]\ttraining's auc: 0.944161\tvalid_1's auc: 0.901474\n",
      "[10000]\ttraining's auc: 0.947588\tvalid_1's auc: 0.901657\n",
      "[11000]\ttraining's auc: 0.950862\tvalid_1's auc: 0.901811\n",
      "[12000]\ttraining's auc: 0.95387\tvalid_1's auc: 0.901698\n",
      "[13000]\ttraining's auc: 0.956852\tvalid_1's auc: 0.9016\n",
      "Early stopping, best iteration is:\n",
      "[10978]\ttraining's auc: 0.950794\tvalid_1's auc: 0.901839\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.893702\tvalid_1's auc: 0.870473\n",
      "[2000]\ttraining's auc: 0.908837\tvalid_1's auc: 0.882139\n",
      "[3000]\ttraining's auc: 0.917743\tvalid_1's auc: 0.887273\n",
      "[4000]\ttraining's auc: 0.92407\tvalid_1's auc: 0.890358\n",
      "[5000]\ttraining's auc: 0.92903\tvalid_1's auc: 0.891806\n",
      "[6000]\ttraining's auc: 0.933458\tvalid_1's auc: 0.892863\n",
      "[7000]\ttraining's auc: 0.937426\tvalid_1's auc: 0.893507\n",
      "[8000]\ttraining's auc: 0.94114\tvalid_1's auc: 0.893923\n",
      "[9000]\ttraining's auc: 0.944621\tvalid_1's auc: 0.894313\n",
      "[10000]\ttraining's auc: 0.94799\tvalid_1's auc: 0.894542\n",
      "[11000]\ttraining's auc: 0.951195\tvalid_1's auc: 0.894398\n",
      "[12000]\ttraining's auc: 0.954184\tvalid_1's auc: 0.894148\n",
      "Early stopping, best iteration is:\n",
      "[10273]\ttraining's auc: 0.948865\tvalid_1's auc: 0.894644\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.89298\tvalid_1's auc: 0.878464\n",
      "[2000]\ttraining's auc: 0.908135\tvalid_1's auc: 0.891839\n",
      "[3000]\ttraining's auc: 0.916967\tvalid_1's auc: 0.897656\n",
      "[4000]\ttraining's auc: 0.923397\tvalid_1's auc: 0.900785\n",
      "[5000]\ttraining's auc: 0.92841\tvalid_1's auc: 0.90252\n",
      "[6000]\ttraining's auc: 0.932793\tvalid_1's auc: 0.903729\n",
      "[7000]\ttraining's auc: 0.936714\tvalid_1's auc: 0.904323\n",
      "[8000]\ttraining's auc: 0.940454\tvalid_1's auc: 0.90481\n",
      "[9000]\ttraining's auc: 0.944007\tvalid_1's auc: 0.904685\n",
      "[10000]\ttraining's auc: 0.947389\tvalid_1's auc: 0.904747\n",
      "[11000]\ttraining's auc: 0.95063\tvalid_1's auc: 0.904664\n",
      "Early stopping, best iteration is:\n",
      "[9495]\ttraining's auc: 0.945713\tvalid_1's auc: 0.904896\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.89391\tvalid_1's auc: 0.868064\n",
      "[2000]\ttraining's auc: 0.909275\tvalid_1's auc: 0.877604\n",
      "[3000]\ttraining's auc: 0.918053\tvalid_1's auc: 0.882574\n",
      "[4000]\ttraining's auc: 0.92447\tvalid_1's auc: 0.885507\n",
      "[5000]\ttraining's auc: 0.929455\tvalid_1's auc: 0.886908\n",
      "[6000]\ttraining's auc: 0.933842\tvalid_1's auc: 0.887833\n",
      "[7000]\ttraining's auc: 0.937761\tvalid_1's auc: 0.88829\n",
      "[8000]\ttraining's auc: 0.94143\tvalid_1's auc: 0.88873\n",
      "[9000]\ttraining's auc: 0.944886\tvalid_1's auc: 0.889096\n",
      "[10000]\ttraining's auc: 0.948231\tvalid_1's auc: 0.889137\n",
      "[11000]\ttraining's auc: 0.951408\tvalid_1's auc: 0.888862\n",
      "Early stopping, best iteration is:\n",
      "[9302]\ttraining's auc: 0.945919\tvalid_1's auc: 0.889184\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.892663\tvalid_1's auc: 0.885733\n",
      "[2000]\ttraining's auc: 0.907683\tvalid_1's auc: 0.897737\n",
      "[3000]\ttraining's auc: 0.916545\tvalid_1's auc: 0.903042\n",
      "[4000]\ttraining's auc: 0.923061\tvalid_1's auc: 0.906259\n",
      "[5000]\ttraining's auc: 0.928186\tvalid_1's auc: 0.907607\n",
      "[6000]\ttraining's auc: 0.93266\tvalid_1's auc: 0.908116\n",
      "[7000]\ttraining's auc: 0.93661\tvalid_1's auc: 0.908291\n",
      "[8000]\ttraining's auc: 0.940329\tvalid_1's auc: 0.90848\n",
      "[9000]\ttraining's auc: 0.943954\tvalid_1's auc: 0.908482\n",
      "[10000]\ttraining's auc: 0.947346\tvalid_1's auc: 0.90829\n",
      "Early stopping, best iteration is:\n",
      "[8401]\ttraining's auc: 0.941793\tvalid_1's auc: 0.908669\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.893832\tvalid_1's auc: 0.867455\n",
      "[2000]\ttraining's auc: 0.908814\tvalid_1's auc: 0.880271\n",
      "[3000]\ttraining's auc: 0.9177\tvalid_1's auc: 0.885291\n",
      "[4000]\ttraining's auc: 0.924125\tvalid_1's auc: 0.888453\n",
      "[5000]\ttraining's auc: 0.929287\tvalid_1's auc: 0.890321\n",
      "[6000]\ttraining's auc: 0.933548\tvalid_1's auc: 0.891213\n",
      "[7000]\ttraining's auc: 0.937447\tvalid_1's auc: 0.891846\n",
      "[8000]\ttraining's auc: 0.941151\tvalid_1's auc: 0.891718\n",
      "[9000]\ttraining's auc: 0.944654\tvalid_1's auc: 0.891639\n",
      "Early stopping, best iteration is:\n",
      "[7093]\ttraining's auc: 0.937782\tvalid_1's auc: 0.891882\n",
      "Fold 6\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.893032\tvalid_1's auc: 0.874933\n",
      "[2000]\ttraining's auc: 0.908248\tvalid_1's auc: 0.887741\n",
      "[3000]\ttraining's auc: 0.917056\tvalid_1's auc: 0.894023\n",
      "[4000]\ttraining's auc: 0.923608\tvalid_1's auc: 0.896986\n",
      "[5000]\ttraining's auc: 0.928743\tvalid_1's auc: 0.898641\n",
      "[6000]\ttraining's auc: 0.933076\tvalid_1's auc: 0.899101\n",
      "[7000]\ttraining's auc: 0.937044\tvalid_1's auc: 0.899678\n",
      "[8000]\ttraining's auc: 0.940718\tvalid_1's auc: 0.899726\n",
      "[9000]\ttraining's auc: 0.944163\tvalid_1's auc: 0.899703\n",
      "[10000]\ttraining's auc: 0.947536\tvalid_1's auc: 0.899939\n",
      "[11000]\ttraining's auc: 0.950755\tvalid_1's auc: 0.899919\n",
      "[12000]\ttraining's auc: 0.953766\tvalid_1's auc: 0.900123\n",
      "[13000]\ttraining's auc: 0.956774\tvalid_1's auc: 0.900244\n",
      "[14000]\ttraining's auc: 0.959648\tvalid_1's auc: 0.900026\n",
      "[15000]\ttraining's auc: 0.962355\tvalid_1's auc: 0.899795\n",
      "Early stopping, best iteration is:\n",
      "[12864]\ttraining's auc: 0.956374\tvalid_1's auc: 0.900373\n",
      "Fold 7\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.892716\tvalid_1's auc: 0.875738\n",
      "[2000]\ttraining's auc: 0.908056\tvalid_1's auc: 0.888373\n",
      "[3000]\ttraining's auc: 0.917116\tvalid_1's auc: 0.894537\n",
      "[4000]\ttraining's auc: 0.923633\tvalid_1's auc: 0.897567\n",
      "[5000]\ttraining's auc: 0.928782\tvalid_1's auc: 0.899512\n",
      "[6000]\ttraining's auc: 0.933116\tvalid_1's auc: 0.900255\n",
      "[7000]\ttraining's auc: 0.937027\tvalid_1's auc: 0.900453\n",
      "[8000]\ttraining's auc: 0.940752\tvalid_1's auc: 0.900837\n",
      "[9000]\ttraining's auc: 0.944294\tvalid_1's auc: 0.901093\n",
      "[10000]\ttraining's auc: 0.947635\tvalid_1's auc: 0.900978\n",
      "[11000]\ttraining's auc: 0.950852\tvalid_1's auc: 0.900919\n",
      "Early stopping, best iteration is:\n",
      "[9166]\ttraining's auc: 0.944875\tvalid_1's auc: 0.901153\n",
      "Fold 8\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.892577\tvalid_1's auc: 0.88069\n",
      "[2000]\ttraining's auc: 0.907829\tvalid_1's auc: 0.892179\n",
      "[3000]\ttraining's auc: 0.916925\tvalid_1's auc: 0.897726\n",
      "[4000]\ttraining's auc: 0.923331\tvalid_1's auc: 0.900299\n",
      "[5000]\ttraining's auc: 0.928479\tvalid_1's auc: 0.90159\n",
      "[6000]\ttraining's auc: 0.932881\tvalid_1's auc: 0.90249\n",
      "[7000]\ttraining's auc: 0.936803\tvalid_1's auc: 0.902661\n",
      "[8000]\ttraining's auc: 0.940528\tvalid_1's auc: 0.90278\n",
      "[9000]\ttraining's auc: 0.944031\tvalid_1's auc: 0.902661\n",
      "[10000]\ttraining's auc: 0.947444\tvalid_1's auc: 0.902695\n",
      "Early stopping, best iteration is:\n",
      "[7520]\ttraining's auc: 0.938761\tvalid_1's auc: 0.902813\n",
      "Fold 9\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.892503\tvalid_1's auc: 0.880802\n",
      "[2000]\ttraining's auc: 0.907814\tvalid_1's auc: 0.891926\n",
      "[3000]\ttraining's auc: 0.917046\tvalid_1's auc: 0.896488\n",
      "[4000]\ttraining's auc: 0.923665\tvalid_1's auc: 0.898752\n",
      "[5000]\ttraining's auc: 0.928786\tvalid_1's auc: 0.900204\n",
      "[6000]\ttraining's auc: 0.933135\tvalid_1's auc: 0.900785\n",
      "[7000]\ttraining's auc: 0.937081\tvalid_1's auc: 0.901156\n",
      "[8000]\ttraining's auc: 0.940768\tvalid_1's auc: 0.901238\n",
      "[9000]\ttraining's auc: 0.944308\tvalid_1's auc: 0.901293\n",
      "[10000]\ttraining's auc: 0.947681\tvalid_1's auc: 0.901498\n",
      "[11000]\ttraining's auc: 0.950954\tvalid_1's auc: 0.901311\n",
      "[12000]\ttraining's auc: 0.953992\tvalid_1's auc: 0.901492\n",
      "Early stopping, best iteration is:\n",
      "[9888]\ttraining's auc: 0.947331\tvalid_1's auc: 0.901549\n",
      "Fold 10\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.893167\tvalid_1's auc: 0.872356\n",
      "[2000]\ttraining's auc: 0.908205\tvalid_1's auc: 0.885729\n",
      "[3000]\ttraining's auc: 0.917141\tvalid_1's auc: 0.891242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4000]\ttraining's auc: 0.923606\tvalid_1's auc: 0.894552\n",
      "[5000]\ttraining's auc: 0.928776\tvalid_1's auc: 0.896523\n",
      "[6000]\ttraining's auc: 0.93316\tvalid_1's auc: 0.897428\n",
      "[7000]\ttraining's auc: 0.937073\tvalid_1's auc: 0.898014\n",
      "[8000]\ttraining's auc: 0.940775\tvalid_1's auc: 0.898121\n",
      "[9000]\ttraining's auc: 0.944347\tvalid_1's auc: 0.898168\n",
      "[10000]\ttraining's auc: 0.947719\tvalid_1's auc: 0.898199\n",
      "[11000]\ttraining's auc: 0.950929\tvalid_1's auc: 0.898217\n",
      "[12000]\ttraining's auc: 0.953946\tvalid_1's auc: 0.897998\n",
      "Early stopping, best iteration is:\n",
      "[10346]\ttraining's auc: 0.948853\tvalid_1's auc: 0.89835\n",
      "Fold 11\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.892966\tvalid_1's auc: 0.880735\n",
      "[2000]\ttraining's auc: 0.907987\tvalid_1's auc: 0.891336\n",
      "[3000]\ttraining's auc: 0.91693\tvalid_1's auc: 0.896565\n",
      "[4000]\ttraining's auc: 0.923361\tvalid_1's auc: 0.899552\n",
      "[5000]\ttraining's auc: 0.928452\tvalid_1's auc: 0.900959\n",
      "[6000]\ttraining's auc: 0.932808\tvalid_1's auc: 0.901502\n",
      "[7000]\ttraining's auc: 0.936752\tvalid_1's auc: 0.901998\n",
      "[8000]\ttraining's auc: 0.940471\tvalid_1's auc: 0.902401\n",
      "[9000]\ttraining's auc: 0.943987\tvalid_1's auc: 0.902465\n",
      "[10000]\ttraining's auc: 0.947358\tvalid_1's auc: 0.9024\n",
      "[11000]\ttraining's auc: 0.950625\tvalid_1's auc: 0.902596\n",
      "[12000]\ttraining's auc: 0.953695\tvalid_1's auc: 0.902437\n",
      "[13000]\ttraining's auc: 0.956629\tvalid_1's auc: 0.902476\n",
      "Early stopping, best iteration is:\n",
      "[11160]\ttraining's auc: 0.951111\tvalid_1's auc: 0.902691\n",
      "Fold 12\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.892965\tvalid_1's auc: 0.881539\n",
      "[2000]\ttraining's auc: 0.90824\tvalid_1's auc: 0.893407\n",
      "[3000]\ttraining's auc: 0.917107\tvalid_1's auc: 0.898372\n",
      "[4000]\ttraining's auc: 0.923444\tvalid_1's auc: 0.9009\n",
      "[5000]\ttraining's auc: 0.928504\tvalid_1's auc: 0.902028\n",
      "[6000]\ttraining's auc: 0.932892\tvalid_1's auc: 0.902542\n",
      "[7000]\ttraining's auc: 0.936874\tvalid_1's auc: 0.902801\n",
      "[8000]\ttraining's auc: 0.940591\tvalid_1's auc: 0.902907\n",
      "[9000]\ttraining's auc: 0.944077\tvalid_1's auc: 0.902724\n",
      "[10000]\ttraining's auc: 0.947401\tvalid_1's auc: 0.902654\n",
      "Early stopping, best iteration is:\n",
      "[7559]\ttraining's auc: 0.938949\tvalid_1's auc: 0.903119\n",
      "Fold 13\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.892824\tvalid_1's auc: 0.884994\n",
      "[2000]\ttraining's auc: 0.907778\tvalid_1's auc: 0.897106\n",
      "[3000]\ttraining's auc: 0.916681\tvalid_1's auc: 0.903121\n",
      "[4000]\ttraining's auc: 0.923071\tvalid_1's auc: 0.9066\n",
      "[5000]\ttraining's auc: 0.928169\tvalid_1's auc: 0.90822\n",
      "[6000]\ttraining's auc: 0.932549\tvalid_1's auc: 0.909211\n",
      "[7000]\ttraining's auc: 0.9365\tvalid_1's auc: 0.909966\n",
      "[8000]\ttraining's auc: 0.940256\tvalid_1's auc: 0.910333\n",
      "[9000]\ttraining's auc: 0.9438\tvalid_1's auc: 0.910145\n",
      "[10000]\ttraining's auc: 0.947211\tvalid_1's auc: 0.910267\n",
      "Early stopping, best iteration is:\n",
      "[7845]\ttraining's auc: 0.939667\tvalid_1's auc: 0.910448\n",
      "Fold 14\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.893442\tvalid_1's auc: 0.878078\n",
      "[2000]\ttraining's auc: 0.908753\tvalid_1's auc: 0.887419\n",
      "[3000]\ttraining's auc: 0.91781\tvalid_1's auc: 0.89156\n",
      "[4000]\ttraining's auc: 0.924162\tvalid_1's auc: 0.893714\n",
      "[5000]\ttraining's auc: 0.929177\tvalid_1's auc: 0.894621\n",
      "[6000]\ttraining's auc: 0.933475\tvalid_1's auc: 0.895187\n",
      "[7000]\ttraining's auc: 0.937417\tvalid_1's auc: 0.895612\n",
      "[8000]\ttraining's auc: 0.941112\tvalid_1's auc: 0.895722\n",
      "[9000]\ttraining's auc: 0.944618\tvalid_1's auc: 0.895766\n",
      "[10000]\ttraining's auc: 0.947948\tvalid_1's auc: 0.896015\n",
      "[11000]\ttraining's auc: 0.951154\tvalid_1's auc: 0.896095\n",
      "[12000]\ttraining's auc: 0.954144\tvalid_1's auc: 0.896242\n",
      "[13000]\ttraining's auc: 0.957143\tvalid_1's auc: 0.89596\n",
      "[14000]\ttraining's auc: 0.960011\tvalid_1's auc: 0.895765\n",
      "Early stopping, best iteration is:\n",
      "[11842]\ttraining's auc: 0.953679\tvalid_1's auc: 0.896285\n",
      "CV score: 0.90030 \n"
     ]
    }
   ],
   "source": [
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(features.values, target.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(features.iloc[trn_idx], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(features.iloc[val_idx], label=target.iloc[val_idx])\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 2500)\n",
    "    oof[val_idx] = clf.predict(features.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "    predictions += clf.predict(test2, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "8d1200f933d8372fd034892ecebc10784534a9b7"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"ID_code\": test.ID_code.values})\n",
    "submission[\"target\"] = predictions\n",
    "submission.to_csv(\"submission_fea.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 100000\n",
    "folds = StratifiedKFold(n_splits=11, shuffle=False, random_state=100)\n",
    "oof = np.zeros(len(features))\n",
    "predictions = np.zeros(len(test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.893944\tvalid_1's auc: 0.874343\n",
      "[2000]\ttraining's auc: 0.908887\tvalid_1's auc: 0.886154\n",
      "[3000]\ttraining's auc: 0.917757\tvalid_1's auc: 0.892307\n",
      "[4000]\ttraining's auc: 0.924132\tvalid_1's auc: 0.895527\n",
      "[5000]\ttraining's auc: 0.929241\tvalid_1's auc: 0.8976\n",
      "[6000]\ttraining's auc: 0.933649\tvalid_1's auc: 0.898635\n",
      "[7000]\ttraining's auc: 0.937649\tvalid_1's auc: 0.899468\n",
      "[8000]\ttraining's auc: 0.941441\tvalid_1's auc: 0.899707\n",
      "[9000]\ttraining's auc: 0.945024\tvalid_1's auc: 0.899848\n",
      "[10000]\ttraining's auc: 0.948485\tvalid_1's auc: 0.900093\n",
      "[11000]\ttraining's auc: 0.951798\tvalid_1's auc: 0.900049\n",
      "[12000]\ttraining's auc: 0.954896\tvalid_1's auc: 0.899939\n",
      "[13000]\ttraining's auc: 0.957871\tvalid_1's auc: 0.899906\n",
      "Early stopping, best iteration is:\n",
      "[11154]\ttraining's auc: 0.952293\tvalid_1's auc: 0.900141\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.893644\tvalid_1's auc: 0.874816\n",
      "[2000]\ttraining's auc: 0.908886\tvalid_1's auc: 0.887245\n",
      "[3000]\ttraining's auc: 0.917898\tvalid_1's auc: 0.892528\n",
      "[4000]\ttraining's auc: 0.924145\tvalid_1's auc: 0.895259\n",
      "[5000]\ttraining's auc: 0.929338\tvalid_1's auc: 0.896506\n",
      "[6000]\ttraining's auc: 0.933768\tvalid_1's auc: 0.897161\n",
      "[7000]\ttraining's auc: 0.937832\tvalid_1's auc: 0.89773\n",
      "[8000]\ttraining's auc: 0.941592\tvalid_1's auc: 0.897759\n",
      "[9000]\ttraining's auc: 0.945204\tvalid_1's auc: 0.89744\n",
      "[10000]\ttraining's auc: 0.948567\tvalid_1's auc: 0.897378\n",
      "Early stopping, best iteration is:\n",
      "[7513]\ttraining's auc: 0.939793\tvalid_1's auc: 0.897793\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.894309\tvalid_1's auc: 0.869194\n",
      "[2000]\ttraining's auc: 0.90961\tvalid_1's auc: 0.880862\n",
      "[3000]\ttraining's auc: 0.918536\tvalid_1's auc: 0.886463\n",
      "[4000]\ttraining's auc: 0.92484\tvalid_1's auc: 0.889156\n",
      "[5000]\ttraining's auc: 0.929923\tvalid_1's auc: 0.890605\n",
      "[6000]\ttraining's auc: 0.93424\tvalid_1's auc: 0.891725\n",
      "[7000]\ttraining's auc: 0.938202\tvalid_1's auc: 0.892127\n",
      "[8000]\ttraining's auc: 0.941979\tvalid_1's auc: 0.892314\n",
      "[9000]\ttraining's auc: 0.945526\tvalid_1's auc: 0.892594\n",
      "[10000]\ttraining's auc: 0.948909\tvalid_1's auc: 0.892546\n",
      "[11000]\ttraining's auc: 0.952131\tvalid_1's auc: 0.892416\n",
      "Early stopping, best iteration is:\n",
      "[9342]\ttraining's auc: 0.946668\tvalid_1's auc: 0.892721\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.893562\tvalid_1's auc: 0.87928\n",
      "[2000]\ttraining's auc: 0.908661\tvalid_1's auc: 0.891183\n",
      "[3000]\ttraining's auc: 0.917646\tvalid_1's auc: 0.896363\n",
      "[4000]\ttraining's auc: 0.924059\tvalid_1's auc: 0.899165\n",
      "[5000]\ttraining's auc: 0.929189\tvalid_1's auc: 0.90039\n",
      "[6000]\ttraining's auc: 0.933627\tvalid_1's auc: 0.900998\n",
      "[7000]\ttraining's auc: 0.937638\tvalid_1's auc: 0.901297\n",
      "[8000]\ttraining's auc: 0.941322\tvalid_1's auc: 0.901437\n",
      "[9000]\ttraining's auc: 0.944929\tvalid_1's auc: 0.901568\n"
     ]
    }
   ],
   "source": [
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(features.values, target.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(features.iloc[trn_idx], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(features.iloc[val_idx], label=target.iloc[val_idx])\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 2500)\n",
    "    oof[val_idx] = clf.predict(features.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "    predictions += clf.predict(test2, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"ID_code\": test.ID_code.values})\n",
    "submission[\"target\"] = predictions\n",
    "submission.to_csv(\"submission_fea2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Neural Network model...\n",
      "Train on 160000 samples, validate on 40000 samples\n",
      "Epoch 1/3\n",
      "160000/160000 [==============================] - 13s 79us/step - loss: 0.3400 - acc: 0.8966 - auc: 0.5225 - val_loss: 0.3253 - val_acc: 0.8988 - val_auc: 0.5317\n",
      "Epoch 2/3\n",
      "160000/160000 [==============================] - 12s 77us/step - loss: 0.3271 - acc: 0.8997 - auc: 0.5358 - val_loss: 0.3225 - val_acc: 0.8988 - val_auc: 0.5419\n",
      "Epoch 3/3\n",
      "160000/160000 [==============================] - 11s 72us/step - loss: 0.3255 - acc: 0.8997 - auc: 0.5450 - val_loss: 0.3207 - val_acc: 0.8988 - val_auc: 0.5490\n"
     ]
    }
   ],
   "source": [
    "print('Building Neural Network model...')\n",
    "adam = optimizers.adam(lr = 0.005, decay = 0.0000001)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(48, input_dim=features.shape[1],\n",
    "                kernel_initializer='normal',\n",
    "                #kernel_regularizer=regularizers.l2(0.02),\n",
    "                activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(24,\n",
    "                #kernel_regularizer=regularizers.l2(0.02),\n",
    "                activation=\"tanh\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics = ['accuracy',auc])\n",
    "\n",
    "history = model.fit(features, target, validation_split=0.2, epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
